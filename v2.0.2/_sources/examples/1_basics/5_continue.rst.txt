
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/1_basics/5_continue.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_examples_1_basics_5_continue.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_1_basics_5_continue.py:


Continue an Optimization
^^^^^^^^^^^^^^^^^^^^^^^^

SMAC can also be continued from a previous run. To do so, it reads in old files (derived from scenario's name,
output_directory and seed) and sets the corresponding components. In this example, an optimization of a simple quadratic
function is continued.

First, after creating a scenario with 50 trials, we run SMAC with overwrite=True. This will
overwrite any previous runs (in case the example was called before). We use a custom callback to artificially stop
this first optimization after 10 trials.

Second, we again run the SMAC optimization using the same scenario, but this time with overwrite=False. As
there already is a previous run with the same meta data, this run will be continued until the 50 trials are reached.

.. GENERATED FROM PYTHON SOURCE LINES 16-101




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [INFO][abstract_initial_design.py:147] Using 10 initial design configurations and 0 additional configurations.
    [INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.
    [INFO][abstract_intensifier.py:515] Added config f09c3b as new incumbent because there are no incumbents yet.
    [INFO][abstract_intensifier.py:590] Added config bec0fc and rejected config f09c3b as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config a34626 and rejected config bec0fc as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config f72805 and rejected config a34626 as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][smbo.py:224] A callback returned False. Abort is requested.
    [INFO][smbo.py:332] Shutting down because the stop flag was set.
    [INFO][abstract_initial_design.py:147] Using 10 initial design configurations and 0 additional configurations.
    [INFO][smbo.py:497] Continuing from previous run.
    [INFO][abstract_intensifier.py:287] Added existing seed 209652396 from runhistory to the intensifier.
    [INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.
    [INFO][abstract_intensifier.py:590] Added config 59460a and rejected config f72805 as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config f74db6 and rejected config 59460a as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config 22beb0 and rejected config f74db6 as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config b07de4 and rejected config 22beb0 as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config 2ec12b and rejected config b07de4 as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config 7ea8bb and rejected config 2ec12b as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config c4859b and rejected config 7ea8bb as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][abstract_intensifier.py:590] Added config e501ff and rejected config c4859b as incumbent because it is not better than the incumbents on 1 instances:
    [INFO][smbo.py:319] Finished 50 trials.
    [INFO][smbo.py:327] Configuration budget is exhausted:
    [INFO][smbo.py:328] --- Remaining wallclock time: inf
    [INFO][smbo.py:329] --- Remaining cpu time: inf
    [INFO][smbo.py:330] --- Remaining trials: 0
    [INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.
    Default cost: 25.0
    Incumbent cost of first run: 0.09616130553975616
    [INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.
    Incumbent cost of continued run: 1.0393385263038637e-07






|

.. code-block:: default


    from __future__ import annotations

    from ConfigSpace import Configuration, ConfigurationSpace, Float

    from smac import Callback
    from smac import HyperparameterOptimizationFacade as HPOFacade
    from smac import Scenario
    from smac.main.smbo import SMBO
    from smac.runhistory import TrialInfo, TrialValue

    __copyright__ = "Copyright 2021, AutoML.org Freiburg-Hannover"
    __license__ = "3-clause BSD"


    class StopCallback(Callback):
        def __init__(self, stop_after: int):
            self._stop_after = stop_after

        def on_tell_end(self, smbo: SMBO, info: TrialInfo, value: TrialValue) -> bool | None:
            """Called after the stats are updated and the trial is added to the runhistory. Optionally, returns false
            to gracefully stop the optimization.
            """
            if smbo.runhistory.finished == self._stop_after:
                return False

            return None


    class QuadraticFunction:
        @property
        def configspace(self) -> ConfigurationSpace:
            cs = ConfigurationSpace(seed=0)
            x = Float("x", (-5, 5), default=-5)
            cs.add_hyperparameters([x])

            return cs

        def train(self, config: Configuration, seed: int = 0) -> float:
            """Returns the y value of a quadratic function with a minimum at x=0."""
            x = config["x"]
            return x * x


    if __name__ == "__main__":
        model = QuadraticFunction()

        # Scenario object specifying the optimization "environment"
        scenario = Scenario(model.configspace, deterministic=True, n_trials=50)
        stop_after = 10

        # Now we use SMAC to find the best hyperparameters
        smac = HPOFacade(
            scenario,
            model.train,  # We pass the target function here
            callbacks=[StopCallback(stop_after=stop_after)],
            overwrite=True,  # Overrides any previous results that are found that are inconsistent with the meta-data
        )

        incumbent = smac.optimize()
        assert smac.runhistory.finished == stop_after

        # Now, we want to continue the optimization
        # Make sure, we don't overwrite the last run
        smac2 = HPOFacade(
            scenario,
            model.train,
            overwrite=False,
        )

        # Check whether we get the same incumbent
        assert smac.intensifier.get_incumbent() == smac2.intensifier.get_incumbent()
        assert smac2.runhistory.finished == stop_after

        # And now we finish the optimization
        incumbent2 = smac2.optimize()

        default_cost = smac.validate(model.configspace.get_default_configuration())
        print(f"Default cost: {default_cost}")

        incumbent_cost = smac.validate(incumbent)
        print(f"Incumbent cost of first run: {incumbent_cost}")

        incumbent_cost = smac2.validate(incumbent2)
        print(f"Incumbent cost of continued run: {incumbent_cost}")


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.118 seconds)


.. _sphx_glr_download_examples_1_basics_5_continue.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/automl/SMAC3/main?urlpath=lab/tree/notebooks/examples/1_basics/5_continue.ipynb
        :alt: Launch binder
        :width: 150 px



    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 5_continue.py <5_continue.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 5_continue.ipynb <5_continue.ipynb>`
