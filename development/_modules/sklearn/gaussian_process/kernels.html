

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sklearn.gaussian_process.kernels &mdash; SMAC 0.10.1.dev documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> SMAC
          

          
            
            <img src="../../../_static/SMAC3.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.10.1.dev
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage_recomendation.html">Usage Recommendation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../manual.html">Manual</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../basic_usage.html">Basic Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../options.html">Options and file formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tae.html">Target Algorithm Evaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../psmac.html">Parallel SMAC (pSMAC)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../validation.html">Validation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.configspace.html">smac.configspace package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.configspace.util.html">smac.configspace.util module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.epm.html">smac.epm package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.base_epm.html">smac.epm.base_epm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.base_gp.html">smac.epm.base_gp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.base_imputor.html">smac.epm.base_imputor module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.base_rf.html">smac.epm.base_rf module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.gaussian_process.html">smac.epm.gaussian_process module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.gaussian_process_mcmc.html">smac.epm.gaussian_process_mcmc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.gp_base_prior.html">smac.epm.gp_base_prior module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.gp_kernels.html">smac.epm.gp_kernels module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.random_epm.html">smac.epm.random_epm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.rf_with_instances.html">smac.epm.rf_with_instances module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.rf_with_instances_hpo.html">smac.epm.rf_with_instances_hpo module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.rfr_imputator.html">smac.epm.rfr_imputator module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.uncorrelated_mo_rf_with_instances.html">smac.epm.uncorrelated_mo_rf_with_instances module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.epm.util_funcs.html">smac.epm.util_funcs module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.facade.html">smac.facade package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.facade.experimental.html">smac.facade.experimental package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.facade.experimental.epils_facade.html">smac.facade.experimental.epils_facade module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.facade.experimental.hydra_facade.html">smac.facade.experimental.hydra_facade module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.facade.experimental.psmac_facade.html">smac.facade.experimental.psmac_facade module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.facade.func_facade.html">smac.facade.func_facade module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.facade.roar_facade.html">smac.facade.roar_facade module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.facade.smac_ac_facade.html">smac.facade.smac_ac_facade module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.facade.smac_bo_facade.html">smac.facade.smac_bo_facade module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.facade.smac_hpo_facade.html">smac.facade.smac_hpo_facade module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.initial_design.html">smac.initial_design package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.initial_design.default_configuration_design.html">smac.initial_design.default_configuration_design module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.initial_design.factorial_design.html">smac.initial_design.factorial_design module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.initial_design.initial_design.html">smac.initial_design.initial_design module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.initial_design.latin_hypercube_design.html">smac.initial_design.latin_hypercube_design module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.initial_design.random_configuration_design.html">smac.initial_design.random_configuration_design module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.initial_design.sobol_design.html">smac.initial_design.sobol_design module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.intensification.html">smac.intensification package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.intensification.intensification.html">smac.intensification.intensification module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.optimizer.html">smac.optimizer package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.acquisition.html">smac.optimizer.acquisition module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.ei_optimization.html">smac.optimizer.ei_optimization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.epils.html">smac.optimizer.epils module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.objective.html">smac.optimizer.objective module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.pSMAC.html">smac.optimizer.pSMAC module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.random_configuration_chooser.html">smac.optimizer.random_configuration_chooser module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.optimizer.smbo.html">smac.optimizer.smbo module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.runhistory.html">smac.runhistory package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.runhistory.runhistory.html">smac.runhistory.runhistory module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.runhistory.runhistory2epm.html">smac.runhistory.runhistory2epm module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.scenario.html">smac.scenario package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.scenario.scenario.html">smac.scenario.scenario module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.stats.html">smac.stats package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.stats.stats.html">smac.stats.stats module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.tae.html">smac.tae package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.tae.execute_func.html">smac.tae.execute_func module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.tae.execute_ta_run.html">smac.tae.execute_ta_run module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.tae.execute_ta_run_aclib.html">smac.tae.execute_ta_run_aclib module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.tae.execute_ta_run_hydra.html">smac.tae.execute_ta_run_hydra module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.tae.execute_ta_run_old.html">smac.tae.execute_ta_run_old module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.utils.html">smac.utils package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.io.html">smac.utils.io package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.utils.io.cmd_reader.html">smac.utils.io.cmd_reader module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.utils.io.input_reader.html">smac.utils.io.input_reader module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.utils.io.output_directory.html">smac.utils.io.output_directory module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.utils.io.output_writer.html">smac.utils.io.output_writer module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../apidoc/smac.utils.io.traj_logging.html">smac.utils.io.traj_logging module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.constants.html">smac.utils.constants module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.dependencies.html">smac.utils.dependencies module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.duplicate_filter_logging.html">smac.utils.duplicate_filter_logging module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.logging.html">smac.utils.logging module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.merge_foreign_data.html">smac.utils.merge_foreign_data module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.test_helpers.html">smac.utils.test_helpers module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../apidoc/smac.utils.validate.html">smac.utils.validate module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../apidoc/smac.smac_cli.html">smac.smac_cli module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">F.A.Q.</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contact.html">Contact</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../license.html">License</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">SMAC</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>sklearn.gaussian_process.kernels</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for sklearn.gaussian_process.kernels</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Kernels for Gaussian process regression and classification.</span>

<span class="sd">The kernels in this module allow kernel-engineering, i.e., they can be</span>
<span class="sd">combined via the &quot;+&quot; and &quot;*&quot; operators or be exponentiated with a scalar</span>
<span class="sd">via &quot;**&quot;. These sum and product expressions can also contain scalar values,</span>
<span class="sd">which are automatically converted to a constant kernel.</span>

<span class="sd">All kernels allow (analytic) gradient-based hyperparameter optimization.</span>
<span class="sd">The space of hyperparameters can be specified by giving lower und upper</span>
<span class="sd">boundaries for the value of each hyperparameter (the search space is thus</span>
<span class="sd">rectangular). Instead of specifying bounds, hyperparameters can also be</span>
<span class="sd">declared to be &quot;fixed&quot;, which causes these hyperparameters to be excluded from</span>
<span class="sd">optimization.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Jan Hendrik Metzen &lt;jhm@informatik.uni-bremen.de&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="c1"># Note: this module is strongly inspired by the kernel module of the george</span>
<span class="c1">#       package.</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="k">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">namedtuple</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="k">import</span> <span class="n">kv</span><span class="p">,</span> <span class="n">gamma</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="k">import</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">cdist</span><span class="p">,</span> <span class="n">squareform</span>

<span class="kn">from</span> <span class="nn">..metrics.pairwise</span> <span class="k">import</span> <span class="n">pairwise_kernels</span>
<span class="kn">from</span> <span class="nn">..externals</span> <span class="k">import</span> <span class="n">six</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="k">import</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">..utils.fixes</span> <span class="k">import</span> <span class="n">signature</span>


<span class="k">def</span> <span class="nf">_check_length_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">length_scale</span><span class="p">):</span>
    <span class="n">length_scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;length_scale cannot be of dimension greater than 1&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">length_scale</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">length_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Anisotropic kernel must have the same number of &quot;</span>
                         <span class="s2">&quot;dimensions as data (</span><span class="si">%d</span><span class="s2">!=</span><span class="si">%d</span><span class="s2">)&quot;</span>
                         <span class="o">%</span> <span class="p">(</span><span class="n">length_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">length_scale</span>


<span class="k">class</span> <span class="nc">Hyperparameter</span><span class="p">(</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Hyperparameter&#39;</span><span class="p">,</span>
                                <span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="s1">&#39;value_type&#39;</span><span class="p">,</span> <span class="s1">&#39;bounds&#39;</span><span class="p">,</span>
                                 <span class="s1">&#39;n_elements&#39;</span><span class="p">,</span> <span class="s1">&#39;fixed&#39;</span><span class="p">))):</span>
    <span class="sd">&quot;&quot;&quot;A kernel hyperparameter&#39;s specification in form of a namedtuple.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    name : string</span>
<span class="sd">        The name of the hyperparameter. Note that a kernel using a</span>
<span class="sd">        hyperparameter with name &quot;x&quot; must have the attributes self.x and</span>
<span class="sd">        self.x_bounds</span>

<span class="sd">    value_type : string</span>
<span class="sd">        The type of the hyperparameter. Currently, only &quot;numeric&quot;</span>
<span class="sd">        hyperparameters are supported.</span>

<span class="sd">    bounds : pair of floats &gt;= 0 or &quot;fixed&quot;</span>
<span class="sd">        The lower and upper bound on the parameter. If n_elements&gt;1, a pair</span>
<span class="sd">        of 1d array with n_elements each may be given alternatively. If</span>
<span class="sd">        the string &quot;fixed&quot; is passed as bounds, the hyperparameter&#39;s value</span>
<span class="sd">        cannot be changed.</span>

<span class="sd">    n_elements : int, default=1</span>
<span class="sd">        The number of elements of the hyperparameter value. Defaults to 1,</span>
<span class="sd">        which corresponds to a scalar hyperparameter. n_elements &gt; 1</span>
<span class="sd">        corresponds to a hyperparameter which is vector-valued,</span>
<span class="sd">        such as, e.g., anisotropic length-scales.</span>

<span class="sd">    fixed : bool, default: None</span>
<span class="sd">        Whether the value of this hyperparameter is fixed, i.e., cannot be</span>
<span class="sd">        changed during hyperparameter tuning. If None is passed, the &quot;fixed&quot; is</span>
<span class="sd">        derived based on the given bounds.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># A raw namedtuple is very memory efficient as it packs the attributes</span>
    <span class="c1"># in a struct to get rid of the __dict__ of attributes in particular it</span>
    <span class="c1"># does not copy the string for the keys on each instance.</span>
    <span class="c1"># By deriving a namedtuple class just to introduce the __init__ method we</span>
    <span class="c1"># would also reintroduce the __dict__ on the instance. By telling the</span>
    <span class="c1"># Python interpreter that this subclass uses static __slots__ instead of</span>
    <span class="c1"># dynamic attributes. Furthermore we don&#39;t need any additional slot in the</span>
    <span class="c1"># subclass so we set __slots__ to the empty tuple.</span>
    <span class="vm">__slots__</span> <span class="o">=</span> <span class="p">()</span>

    <span class="k">def</span> <span class="nf">__new__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value_type</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">n_elements</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fixed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">or</span> <span class="n">bounds</span> <span class="o">!=</span> <span class="s2">&quot;fixed&quot;</span><span class="p">:</span>
            <span class="n">bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">n_elements</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># vector-valued parameter</span>
                <span class="k">if</span> <span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">bounds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">n_elements</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">n_elements</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Bounds on </span><span class="si">%s</span><span class="s2"> should have either 1 or &quot;</span>
                                     <span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> dimensions. Given are </span><span class="si">%d</span><span class="s2">&quot;</span>
                                     <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">n_elements</span><span class="p">,</span> <span class="n">bounds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="k">if</span> <span class="n">fixed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fixed</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bounds</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span> <span class="n">bounds</span> <span class="o">==</span> <span class="s2">&quot;fixed&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">Hyperparameter</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span>
            <span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">value_type</span><span class="p">,</span> <span class="n">bounds</span><span class="p">,</span> <span class="n">n_elements</span><span class="p">,</span> <span class="n">fixed</span><span class="p">)</span>

    <span class="c1"># This is mainly a testing utility to check that two hyperparameters</span>
    <span class="c1"># are equal.</span>
    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">name</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">value_type</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">value_type</span> <span class="ow">and</span>
                <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bounds</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_elements</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">n_elements</span> <span class="ow">and</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fixed</span> <span class="o">==</span> <span class="n">other</span><span class="o">.</span><span class="n">fixed</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Kernel</span><span class="p">(</span><span class="n">six</span><span class="o">.</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ABCMeta</span><span class="p">)):</span>
    <span class="sd">&quot;&quot;&quot;Base class for all kernels.</span>

<span class="sd">    .. versionadded:: 0.18</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get parameters of this kernel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        deep : boolean, optional</span>
<span class="sd">            If True, will return the parameters for this estimator and</span>
<span class="sd">            contained subobjects that are estimators.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : mapping of string to any</span>
<span class="sd">            Parameter names mapped to their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># introspect the constructor arguments to find the model parameters</span>
        <span class="c1"># to represent</span>
        <span class="bp">cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span>
        <span class="n">init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span> <span class="s1">&#39;deprecated_original&#39;</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
        <span class="n">init_sign</span> <span class="o">=</span> <span class="n">signature</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="n">args</span><span class="p">,</span> <span class="n">varargs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">init_sign</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">parameter</span><span class="o">.</span><span class="n">VAR_KEYWORD</span> <span class="ow">and</span>
                    <span class="n">parameter</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s1">&#39;self&#39;</span><span class="p">):</span>
                <span class="n">args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">parameter</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">parameter</span><span class="o">.</span><span class="n">VAR_POSITIONAL</span><span class="p">:</span>
                <span class="n">varargs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameter</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">varargs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;scikit-learn kernels should always &quot;</span>
                               <span class="s2">&quot;specify their parameters in the signature&quot;</span>
                               <span class="s2">&quot; of their __init__ (no varargs).&quot;</span>
                               <span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> doesn&#39;t follow this convention.&quot;</span>
                               <span class="o">%</span> <span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="p">))</span>
        <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
            <span class="n">params</span><span class="p">[</span><span class="n">arg</span><span class="p">]</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">params</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the parameters of this kernel.</span>

<span class="sd">        The method works on simple kernels as well as on nested kernels.</span>
<span class="sd">        The latter have parameters of the form ``&lt;component&gt;__&lt;parameter&gt;``</span>
<span class="sd">        so that it&#39;s possible to update each component of a nested object.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
            <span class="c1"># Simple optimisation to gain speed (inspect is slow)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">iteritems</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
            <span class="n">split</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">split</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># nested objects case</span>
                <span class="n">name</span><span class="p">,</span> <span class="n">sub_name</span> <span class="o">=</span> <span class="n">split</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for kernel </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                     <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                     <span class="s1">&#39;with `kernel.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                     <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>
                <span class="n">sub_object</span> <span class="o">=</span> <span class="n">valid_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
                <span class="n">sub_object</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span><span class="n">sub_name</span><span class="p">:</span> <span class="n">value</span><span class="p">})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># simple objects case</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid parameter </span><span class="si">%s</span><span class="s1"> for kernel </span><span class="si">%s</span><span class="s1">. &#39;</span>
                                     <span class="s1">&#39;Check the list of available parameters &#39;</span>
                                     <span class="s1">&#39;with `kernel.get_params().keys()`.&#39;</span> <span class="o">%</span>
                                     <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">clone_with_theta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a clone of self with given hyperparameters theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The hyperparameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cloned</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">cloned</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="k">return</span> <span class="n">cloned</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of non-fixed hyperparameters of the kernel.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a list of all hyperparameter specifications.&quot;&quot;&quot;</span>
        <span class="n">r</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">attr</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;hyperparameter_&quot;</span><span class="p">):</span>
                <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Note that theta are typically the log-transformed values of the</span>
<span class="sd">        kernel&#39;s hyperparameters as this representation of the search space</span>
<span class="sd">        is more amenable for hyperparameter search, as hyperparameters like</span>
<span class="sd">        length-scales naturally live on a log-scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">hyperparameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">theta</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="n">hyperparameter</span><span class="o">.</span><span class="n">name</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

    <span class="nd">@theta</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">hyperparameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">n_elements</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># vector-valued parameter</span>
                <span class="n">params</span><span class="p">[</span><span class="n">hyperparameter</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span>
                    <span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">n_elements</span><span class="p">])</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">n_elements</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">params</span><span class="p">[</span><span class="n">hyperparameter</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta has not the correct number of entries.&quot;</span>
                             <span class="s2">&quot; Should be </span><span class="si">%d</span><span class="s2">; given are </span><span class="si">%d</span><span class="s2">&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the log-transformed bounds on the theta.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bounds : array, shape (n_dims, 2)</span>
<span class="sd">            The log-transformed bounds on the kernel&#39;s hyperparameters theta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bounds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyperparameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">bounds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyperparameter</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bounds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">bounds</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

    <span class="k">def</span> <span class="nf">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__radd__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Sum</span><span class="p">(</span><span class="n">ConstantKernel</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Sum</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__rmul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">Product</span><span class="p">(</span><span class="n">ConstantKernel</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Product</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__pow__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Exponentiation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="n">params_a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
        <span class="n">params_b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">params_a</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">params_b</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">params_a</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">!=</span> <span class="n">params_b</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)):</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(</span><span class="si">{1}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                                 <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">)))</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluate the kernel.&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>


<span class="k">class</span> <span class="nc">NormalizedKernelMixin</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Mixin for kernels which are normalized: k(X, X)=1.</span>

<span class="sd">    .. versionadded:: 0.18</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">StationaryKernelMixin</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Mixin for kernels which are stationary: k(X, Y)= f(X-Y).</span>

<span class="sd">    .. versionadded:: 0.18</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="k">class</span> <span class="nc">CompoundKernel</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Kernel which is composed of a set of other kernels.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kernels : list of Kernel objects</span>
<span class="sd">        The other kernels</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernels</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span> <span class="o">=</span> <span class="n">kernels</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get parameters of this kernel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        deep : boolean, optional</span>
<span class="sd">            If True, will return the parameters for this estimator and</span>
<span class="sd">            contained subobjects that are estimators.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : mapping of string to any</span>
<span class="sd">            Parameter names mapped to their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kernels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Note that theta are typically the log-transformed values of the</span>
<span class="sd">        kernel&#39;s hyperparameters as this representation of the search space</span>
<span class="sd">        is more amenable for hyperparameter search, as hyperparameters like</span>
<span class="sd">        length-scales naturally live on a log-scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">kernel</span><span class="o">.</span><span class="n">theta</span> <span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">])</span>

    <span class="nd">@theta</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">n_dims</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">):</span>
            <span class="n">kernel</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">k_dims</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">k_dims</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the log-transformed bounds on the theta.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bounds : array, shape (n_dims, 2)</span>
<span class="sd">            The log-transformed bounds on the kernel&#39;s hyperparameters theta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">kernel</span><span class="o">.</span><span class="n">bounds</span> <span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Note that this compound kernel returns the results of all simple kernel</span>
<span class="sd">        stacked along an additional axis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y, n_kernels)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array, shape (n_samples_X, n_samples_X, n_dims, n_kernels)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">K_grad</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">:</span>
                <span class="n">K_single</span><span class="p">,</span> <span class="n">K_grad_single</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="p">)</span>
                <span class="n">K</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K_single</span><span class="p">)</span>
                <span class="n">K_grad</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K_grad_single</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span><span class="n">K</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">K_grad</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="p">)</span>
                              <span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">kernels</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                       <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">))])</span>

    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">([</span><span class="n">kernel</span><span class="o">.</span><span class="n">is_stationary</span><span class="p">()</span> <span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X, n_kernels)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">kernel</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernels</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>


<span class="k">class</span> <span class="nc">KernelOperator</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for all kernel operators.</span>

<span class="sd">    .. versionadded:: 0.18</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k1</span> <span class="o">=</span> <span class="n">k1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k2</span> <span class="o">=</span> <span class="n">k2</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get parameters of this kernel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        deep : boolean, optional</span>
<span class="sd">            If True, will return the parameters for this estimator and</span>
<span class="sd">            contained subobjects that are estimators.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : mapping of string to any</span>
<span class="sd">            Parameter names mapped to their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">k1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">deep</span><span class="p">:</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="s1">&#39;k1__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="s1">&#39;k2__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">params</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a list of all hyperparameter.&quot;&quot;&quot;</span>
        <span class="n">r</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyperparameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">:</span>
            <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;k1__&quot;</span> <span class="o">+</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">value_type</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">n_elements</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">hyperparameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">:</span>
            <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;k2__&quot;</span> <span class="o">+</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">value_type</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">n_elements</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Note that theta are typically the log-transformed values of the</span>
<span class="sd">        kernel&#39;s hyperparameters as this representation of the search space</span>
<span class="sd">        is more amenable for hyperparameter search, as hyperparameters like</span>
<span class="sd">        length-scales naturally live on a log-scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>

    <span class="nd">@theta</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k1_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">n_dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[:</span><span class="n">k1_dims</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="n">k1_dims</span><span class="p">:]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the log-transformed bounds on the theta.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bounds : array, shape (n_dims, 2)</span>
<span class="sd">            The log-transformed bounds on the kernel&#39;s hyperparameters theta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">bounds</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">bounds</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">bounds</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">bounds</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">k1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">k2</span><span class="p">)</span> \
            <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">k2</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">k1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">is_stationary</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">is_stationary</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">Sum</span><span class="p">(</span><span class="n">KernelOperator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sum-kernel k1 + k2 of two kernels k1 and k2.</span>

<span class="sd">    The resulting kernel is defined as</span>
<span class="sd">    k_sum(X, Y) = k1(X, Y) + k2(X, Y)</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k1 : Kernel object</span>
<span class="sd">        The first base-kernel of the sum-kernel</span>

<span class="sd">    k2 : Kernel object</span>
<span class="sd">        The second base-kernel of the sum-kernel</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">K1</span><span class="p">,</span> <span class="n">K1_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">K2</span><span class="p">,</span> <span class="n">K2_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">K1</span> <span class="o">+</span> <span class="n">K2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">K1_gradient</span><span class="p">,</span> <span class="n">K2_gradient</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<div class="viewcode-block" id="Sum.diag"><a class="viewcode-back" href="../../../apidoc/smac.epm.gp_kernels.html#smac.epm.gp_kernels.Sum.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> + </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Product</span><span class="p">(</span><span class="n">KernelOperator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Product-kernel k1 * k2 of two kernels k1 and k2.</span>

<span class="sd">    The resulting kernel is defined as</span>
<span class="sd">    k_prod(X, Y) = k1(X, Y) * k2(X, Y)</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    k1 : Kernel object</span>
<span class="sd">        The first base-kernel of the product-kernel</span>

<span class="sd">    k2 : Kernel object</span>
<span class="sd">        The second base-kernel of the product-kernel</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">K1</span><span class="p">,</span> <span class="n">K1_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">K2</span><span class="p">,</span> <span class="n">K2_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">K1</span> <span class="o">*</span> <span class="n">K2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">K1_gradient</span> <span class="o">*</span> <span class="n">K2</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
                                       <span class="n">K2_gradient</span> <span class="o">*</span> <span class="n">K1</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<div class="viewcode-block" id="Product.diag"><a class="viewcode-back" href="../../../apidoc/smac.epm.gp_kernels.html#smac.epm.gp_kernels.Product.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> * </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k2</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Exponentiation</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Exponentiate kernel by given exponent.</span>

<span class="sd">    The resulting kernel is defined as</span>
<span class="sd">    k_exp(X, Y) = k(X, Y) ** exponent</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kernel : Kernel object</span>
<span class="sd">        The base kernel</span>

<span class="sd">    exponent : float</span>
<span class="sd">        The exponent for the base kernel</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">exponent</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">=</span> <span class="n">exponent</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get parameters of this kernel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        deep : boolean, optional</span>
<span class="sd">            If True, will return the parameters for this estimator and</span>
<span class="sd">            contained subobjects that are estimators.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : mapping of string to any</span>
<span class="sd">            Parameter names mapped to their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">exponent</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exponent</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">deep</span><span class="p">:</span>
            <span class="n">deep_items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="s1">&#39;kernel__&#39;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">params</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a list of all hyperparameter.&quot;&quot;&quot;</span>
        <span class="n">r</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">hyperparameter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">hyperparameters</span><span class="p">:</span>
            <span class="n">r</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;kernel__&quot;</span> <span class="o">+</span> <span class="n">hyperparameter</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">value_type</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span>
                                    <span class="n">hyperparameter</span><span class="o">.</span><span class="n">n_elements</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Note that theta are typically the log-transformed values of the</span>
<span class="sd">        kernel&#39;s hyperparameters as this representation of the search space</span>
<span class="sd">        is more amenable for hyperparameter search, as hyperparameters like</span>
<span class="sd">        length-scales naturally live on a log-scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">theta</span>

    <span class="nd">@theta</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">theta</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the (flattened, log-transformed) non-fixed hyperparameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : array, shape (n_dims,)</span>
<span class="sd">            The non-fixed, log-transformed hyperparameters of the kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bounds</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the log-transformed bounds on the theta.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bounds : array, shape (n_dims, 2)</span>
<span class="sd">            The log-transformed bounds on the kernel&#39;s hyperparameters theta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">bounds</span>

    <span class="k">def</span> <span class="nf">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">==</span> <span class="n">b</span><span class="o">.</span><span class="n">exponent</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">K_gradient</span> <span class="o">*=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">*</span> <span class="n">K</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">K</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span><span class="p">,</span> <span class="n">K_gradient</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">K</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span>

    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2"> ** </span><span class="si">{1}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">is_stationary</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">ConstantKernel</span><span class="p">(</span><span class="n">StationaryKernelMixin</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constant kernel.</span>

<span class="sd">    Can be used as part of a product-kernel where it scales the magnitude of</span>
<span class="sd">    the other factor (kernel) or as part of a sum-kernel, where it modifies</span>
<span class="sd">    the mean of the Gaussian process.</span>

<span class="sd">    k(x_1, x_2) = constant_value for all x_1, x_2</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    constant_value : float, default: 1.0</span>
<span class="sd">        The constant value which defines the covariance:</span>
<span class="sd">        k(x_1, x_2) = constant_value</span>

<span class="sd">    constant_value_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on constant_value</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">constant_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">constant_value_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span> <span class="o">=</span> <span class="n">constant_value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">constant_value_bounds</span> <span class="o">=</span> <span class="n">constant_value_bounds</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_constant_value</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span>
            <span class="s2">&quot;constant_value&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">constant_value_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Y</span> <span class="o">=</span> <span class="n">X</span>
        <span class="k">elif</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>

        <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_constant_value</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">,</span>
                                   <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

<div class="viewcode-block" id="ConstantKernel.diag"><a class="viewcode-back" href="../../../apidoc/smac.epm.gp_kernels.html#smac.epm.gp_kernels.ConstantKernel.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">,</span>
                       <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0:.3g}</span><span class="s2">**2&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">constant_value</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">WhiteKernel</span><span class="p">(</span><span class="n">StationaryKernelMixin</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;White kernel.</span>

<span class="sd">    The main use-case of this kernel is as part of a sum-kernel where it</span>
<span class="sd">    explains the noise-component of the signal. Tuning its parameter</span>
<span class="sd">    corresponds to estimating the noise-level.</span>

<span class="sd">    k(x_1, x_2) = noise_level if x_1 == x_2 else 0</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    noise_level : float, default: 1.0</span>
<span class="sd">        Parameter controlling the noise level</span>

<span class="sd">    noise_level_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on noise_level</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noise_level</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">noise_level_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span> <span class="o">=</span> <span class="n">noise_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_level_bounds</span> <span class="o">=</span> <span class="n">noise_level_bounds</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_noise_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span>
            <span class="s2">&quot;noise_level&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_level_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_noise_level</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span>
                            <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">K</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<div class="viewcode-block" id="WhiteKernel.diag"><a class="viewcode-back" href="../../../apidoc/smac.epm.gp_kernels.html#smac.epm.gp_kernels.WhiteKernel.diag">[docs]</a>    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span><span class="p">,</span>
                       <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(noise_level=</span><span class="si">{1:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">noise_level</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">RBF</span><span class="p">(</span><span class="n">StationaryKernelMixin</span><span class="p">,</span> <span class="n">NormalizedKernelMixin</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Radial-basis function kernel (aka squared-exponential kernel).</span>

<span class="sd">    The RBF kernel is a stationary kernel. It is also known as the</span>
<span class="sd">    &quot;squared exponential&quot; kernel. It is parameterized by a length-scale</span>
<span class="sd">    parameter length_scale&gt;0, which can either be a scalar (isotropic variant</span>
<span class="sd">    of the kernel) or a vector with the same number of dimensions as the inputs</span>
<span class="sd">    X (anisotropic variant of the kernel). The kernel is given by:</span>

<span class="sd">    k(x_i, x_j) = exp(-1 / 2 d(x_i / length_scale, x_j / length_scale)^2)</span>

<span class="sd">    This kernel is infinitely differentiable, which implies that GPs with this</span>
<span class="sd">    kernel as covariance function have mean square derivatives of all orders,</span>
<span class="sd">    and are thus very smooth.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    length_scale : float or array with shape (n_features,), default: 1.0</span>
<span class="sd">        The length scale of the kernel. If a float, an isotropic kernel is</span>
<span class="sd">        used. If an array, an anisotropic kernel is used where each dimension</span>
<span class="sd">        of l defines the length-scale of the respective feature dimension.</span>

<span class="sd">    length_scale_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on length_scale</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">length_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span> <span class="o">=</span> <span class="n">length_scale_bounds</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">anisotropic</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">iterable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_length_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;length_scale&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span><span class="p">,</span>
                                  <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span>
            <span class="s2">&quot;length_scale&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="n">_check_length_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">pdist</span><span class="p">(</span><span class="n">X</span> <span class="o">/</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">dists</span><span class="p">)</span>
            <span class="c1"># convert from upper-triangular matrix to square matrix</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">X</span> <span class="o">/</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">Y</span> <span class="o">/</span> <span class="n">length_scale</span><span class="p">,</span>
                          <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">dists</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_length_scale</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="c1"># Hyperparameter l kept fixed</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span> <span class="ow">or</span> <span class="n">length_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">K_gradient</span> <span class="o">=</span> \
                    <span class="p">(</span><span class="n">K</span> <span class="o">*</span> <span class="n">squareform</span><span class="p">(</span><span class="n">dists</span><span class="p">))[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span><span class="p">:</span>
                <span class="c1"># We need to recompute the pairwise dimension-wise distances</span>
                <span class="n">K_gradient</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mi">2</span> \
                    <span class="o">/</span> <span class="p">(</span><span class="n">length_scale</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">K_gradient</span> <span class="o">*=</span> <span class="n">K</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(length_scale=[</span><span class="si">{1}</span><span class="s2">])&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">,</span>
                                                   <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># isotropic</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(length_scale=</span><span class="si">{1:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">Matern</span><span class="p">(</span><span class="n">RBF</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Matern kernel.</span>

<span class="sd">    The class of Matern kernels is a generalization of the RBF and the</span>
<span class="sd">    absolute exponential kernel parameterized by an additional parameter</span>
<span class="sd">    nu. The smaller nu, the less smooth the approximated function is.</span>
<span class="sd">    For nu=inf, the kernel becomes equivalent to the RBF kernel and for nu=0.5</span>
<span class="sd">    to the absolute exponential kernel. Important intermediate values are</span>
<span class="sd">    nu=1.5 (once differentiable functions) and nu=2.5 (twice differentiable</span>
<span class="sd">    functions).</span>

<span class="sd">    See Rasmussen and Williams 2006, pp84 for details regarding the</span>
<span class="sd">    different variants of the Matern kernel.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    length_scale : float or array with shape (n_features,), default: 1.0</span>
<span class="sd">        The length scale of the kernel. If a float, an isotropic kernel is</span>
<span class="sd">        used. If an array, an anisotropic kernel is used where each dimension</span>
<span class="sd">        of l defines the length-scale of the respective feature dimension.</span>

<span class="sd">    length_scale_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on length_scale</span>

<span class="sd">    nu : float, default: 1.5</span>
<span class="sd">        The parameter nu controlling the smoothness of the learned function.</span>
<span class="sd">        The smaller nu, the less smooth the approximated function is.</span>
<span class="sd">        For nu=inf, the kernel becomes equivalent to the RBF kernel and for</span>
<span class="sd">        nu=0.5 to the absolute exponential kernel. Important intermediate</span>
<span class="sd">        values are nu=1.5 (once differentiable functions) and nu=2.5</span>
<span class="sd">        (twice differentiable functions). Note that values of nu not in</span>
<span class="sd">        [0.5, 1.5, 2.5, inf] incur a considerably higher computational cost</span>
<span class="sd">        (appr. 10 times higher) since they require to evaluate the modified</span>
<span class="sd">        Bessel function. Furthermore, in contrast to l, nu is kept fixed to</span>
<span class="sd">        its initial value and not optimized.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">),</span>
                 <span class="n">nu</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Matern</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">length_scale</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">=</span> <span class="n">nu</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">length_scale</span> <span class="o">=</span> <span class="n">_check_length_scale</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">pdist</span><span class="p">(</span><span class="n">X</span> <span class="o">/</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">X</span> <span class="o">/</span> <span class="n">length_scale</span><span class="p">,</span> <span class="n">Y</span> <span class="o">/</span> <span class="n">length_scale</span><span class="p">,</span>
                          <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dists</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mf">1.5</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">K</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">K</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mf">2.5</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">K</span> <span class="o">+</span> <span class="n">K</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mf">3.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">K</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># general case; expensive to evaluate</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">dists</span>
            <span class="n">K</span><span class="p">[</span><span class="n">K</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>  <span class="c1"># strict zeros result in nan</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">)</span> <span class="o">*</span> <span class="n">K</span><span class="p">)</span>
            <span class="n">K</span><span class="o">.</span><span class="n">fill</span><span class="p">((</span><span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">))</span> <span class="o">/</span> <span class="n">gamma</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">))</span>
            <span class="n">K</span> <span class="o">*=</span> <span class="n">tmp</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span>
            <span class="n">K</span> <span class="o">*=</span> <span class="n">kv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">,</span> <span class="n">tmp</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># convert from upper-triangular matrix to square matrix</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
            <span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_length_scale</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="c1"># Hyperparameter l kept fixed</span>
                <span class="n">K_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span>

            <span class="c1"># We need to recompute the pairwise dimension-wise distances</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span><span class="p">:</span>
                <span class="n">D</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span> \
                    <span class="o">/</span> <span class="p">(</span><span class="n">length_scale</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">D</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">dists</span><span class="o">**</span><span class="mi">2</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">K_gradient</span> <span class="o">=</span> <span class="n">K</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">D</span> \
                    <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span><span class="p">))[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                <span class="n">K_gradient</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">K_gradient</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mf">1.5</span><span class="p">:</span>
                <span class="n">K_gradient</span> <span class="o">=</span> \
                    <span class="mi">3</span> <span class="o">*</span> <span class="n">D</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">D</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)))[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">nu</span> <span class="o">==</span> <span class="mf">2.5</span><span class="p">:</span>
                <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">D</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                <span class="n">K_gradient</span> <span class="o">=</span> <span class="mf">5.0</span> <span class="o">/</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="n">D</span> <span class="o">*</span> <span class="p">(</span><span class="n">tmp</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">tmp</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># approximate gradient numerically</span>
                <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">theta</span><span class="p">):</span>  <span class="c1"># helper function</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone_with_theta</span><span class="p">(</span><span class="n">theta</span><span class="p">)(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">_approx_fprime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span><span class="p">[:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">anisotropic</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(length_scale=[</span><span class="si">{1}</span><span class="s2">], nu=</span><span class="si">{2:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{0:.3g}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(length_scale=</span><span class="si">{1:.3g}</span><span class="s2">, nu=</span><span class="si">{2:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nu</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">RationalQuadratic</span><span class="p">(</span><span class="n">StationaryKernelMixin</span><span class="p">,</span> <span class="n">NormalizedKernelMixin</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Rational Quadratic kernel.</span>

<span class="sd">    The RationalQuadratic kernel can be seen as a scale mixture (an infinite</span>
<span class="sd">    sum) of RBF kernels with different characteristic length-scales. It is</span>
<span class="sd">    parameterized by a length-scale parameter length_scale&gt;0 and a scale</span>
<span class="sd">    mixture parameter alpha&gt;0. Only the isotropic variant where length_scale is</span>
<span class="sd">    a scalar is supported at the moment. The kernel given by:</span>

<span class="sd">    k(x_i, x_j) = (1 + d(x_i, x_j)^2 / (2*alpha * length_scale^2))^-alpha</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    length_scale : float &gt; 0, default: 1.0</span>
<span class="sd">        The length scale of the kernel.</span>

<span class="sd">    alpha : float &gt; 0, default: 1.0</span>
<span class="sd">        Scale mixture parameter</span>

<span class="sd">    length_scale_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on length_scale</span>

<span class="sd">    alpha_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on alpha</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">),</span> <span class="n">alpha_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">length_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span> <span class="o">=</span> <span class="n">length_scale_bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_bounds</span> <span class="o">=</span> <span class="n">alpha_bounds</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_length_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span>
            <span class="s2">&quot;length_scale&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_alpha</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">pdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">))</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">dists</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">base</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">tmp</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">base</span> <span class="o">**</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>
            <span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;sqeuclidean&#39;</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">dists</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span> \
                <span class="o">**</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="c1"># gradient with respect to length_scale</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_length_scale</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">length_scale_gradient</span> <span class="o">=</span> \
                    <span class="n">dists</span> <span class="o">*</span> <span class="n">K</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">base</span><span class="p">)</span>
                <span class="n">length_scale_gradient</span> <span class="o">=</span> <span class="n">length_scale_gradient</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># l is kept fixed</span>
                <span class="n">length_scale_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>

            <span class="c1"># gradient with respect to alpha</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_alpha</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">alpha_gradient</span> <span class="o">=</span> \
                    <span class="n">K</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">base</span><span class="p">)</span>
                         <span class="o">+</span> <span class="n">dists</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">base</span><span class="p">))</span>
                <span class="n">alpha_gradient</span> <span class="o">=</span> <span class="n">alpha_gradient</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># alpha is kept fixed</span>
                <span class="n">alpha_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">alpha_gradient</span><span class="p">,</span> <span class="n">length_scale_gradient</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(alpha=</span><span class="si">{1:.3g}</span><span class="s2">, length_scale=</span><span class="si">{2:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ExpSineSquared</span><span class="p">(</span><span class="n">StationaryKernelMixin</span><span class="p">,</span> <span class="n">NormalizedKernelMixin</span><span class="p">,</span> <span class="n">Kernel</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Exp-Sine-Squared kernel.</span>

<span class="sd">    The ExpSineSquared kernel allows modeling periodic functions. It is</span>
<span class="sd">    parameterized by a length-scale parameter length_scale&gt;0 and a periodicity</span>
<span class="sd">    parameter periodicity&gt;0. Only the isotropic variant where l is a scalar is</span>
<span class="sd">    supported at the moment. The kernel given by:</span>

<span class="sd">    k(x_i, x_j) =</span>
<span class="sd">    exp(-2 (sin(\pi / periodicity * d(x_i, x_j)) / length_scale) ^ 2)</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    length_scale : float &gt; 0, default: 1.0</span>
<span class="sd">        The length scale of the kernel.</span>

<span class="sd">    periodicity : float &gt; 0, default: 1.0</span>
<span class="sd">        The periodicity of the kernel.</span>

<span class="sd">    length_scale_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on length_scale</span>

<span class="sd">    periodicity_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on periodicity</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">periodicity</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">),</span>
                 <span class="n">periodicity_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span> <span class="o">=</span> <span class="n">length_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">periodicity</span> <span class="o">=</span> <span class="n">periodicity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span> <span class="o">=</span> <span class="n">length_scale_bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">periodicity_bounds</span> <span class="o">=</span> <span class="n">periodicity_bounds</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_length_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span>
            <span class="s2">&quot;length_scale&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale_bounds</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_periodicity</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span>
            <span class="s2">&quot;periodicity&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">periodicity_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">pdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))</span>
            <span class="n">arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">dists</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">periodicity</span>
            <span class="n">sin_of_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">sin_of_arg</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>
            <span class="n">dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">periodicity</span> <span class="o">*</span> <span class="n">dists</span><span class="p">)</span>
                              <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">cos_of_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
            <span class="c1"># gradient with respect to length_scale</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_length_scale</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">length_scale_gradient</span> <span class="o">=</span> \
                    <span class="mi">4</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sin_of_arg</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">K</span>
                <span class="n">length_scale_gradient</span> <span class="o">=</span> <span class="n">length_scale_gradient</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># length_scale is kept fixed</span>
                <span class="n">length_scale_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
            <span class="c1"># gradient with respect to p</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_periodicity</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">periodicity_gradient</span> <span class="o">=</span> \
                    <span class="mi">4</span> <span class="o">*</span> <span class="n">arg</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">cos_of_arg</span> \
                    <span class="o">*</span> <span class="n">sin_of_arg</span> <span class="o">*</span> <span class="n">K</span>
                <span class="n">periodicity_gradient</span> <span class="o">=</span> <span class="n">periodicity_gradient</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># p is kept fixed</span>
                <span class="n">periodicity_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">((</span><span class="n">length_scale_gradient</span><span class="p">,</span> <span class="n">periodicity_gradient</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(length_scale=</span><span class="si">{1:.3g}</span><span class="s2">, periodicity=</span><span class="si">{2:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_scale</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">periodicity</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">DotProduct</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Dot-Product kernel.</span>

<span class="sd">    The DotProduct kernel is non-stationary and can be obtained from linear</span>
<span class="sd">    regression by putting N(0, 1) priors on the coefficients of x_d (d = 1, . .</span>
<span class="sd">    . , D) and a prior of N(0, \sigma_0^2) on the bias. The DotProduct kernel</span>
<span class="sd">    is invariant to a rotation of the coordinates about the origin, but not</span>
<span class="sd">    translations. It is parameterized by a parameter sigma_0^2. For</span>
<span class="sd">    sigma_0^2 =0, the kernel is called the homogeneous linear kernel, otherwise</span>
<span class="sd">    it is inhomogeneous. The kernel is given by</span>

<span class="sd">    k(x_i, x_j) = sigma_0 ^ 2 + x_i \cdot x_j</span>

<span class="sd">    The DotProduct kernel is commonly combined with exponentiation.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sigma_0 : float &gt;= 0, default: 1.0</span>
<span class="sd">        Parameter controlling the inhomogenity of the kernel. If sigma_0=0,</span>
<span class="sd">        the kernel is homogenous.</span>

<span class="sd">    sigma_0_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on l</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma_0</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">sigma_0_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">)):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0</span> <span class="o">=</span> <span class="n">sigma_0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0_bounds</span> <span class="o">=</span> <span class="n">sigma_0_bounds</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_sigma_0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;sigma_0&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">Y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Gradient can only be evaluated when Y is None.&quot;</span><span class="p">)</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0</span> <span class="o">**</span> <span class="mi">2</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_sigma_0</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="n">K_gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
                <span class="n">K_gradient</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0</span> <span class="o">**</span> <span class="mi">2</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ij-&gt;i&#39;</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0</span> <span class="o">**</span> <span class="mi">2</span>

    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(sigma_0=</span><span class="si">{1:.3g}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_0</span><span class="p">)</span>


<span class="c1"># adapted from scipy/optimize/optimize.py for functions with 2d output</span>
<span class="k">def</span> <span class="nf">_approx_fprime</span><span class="p">(</span><span class="n">xk</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">()):</span>
    <span class="n">f0</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="p">((</span><span class="n">xk</span><span class="p">,)</span> <span class="o">+</span> <span class="n">args</span><span class="p">))</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">f0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">f0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">xk</span><span class="p">)),</span> <span class="nb">float</span><span class="p">)</span>
    <span class="n">ei</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">xk</span><span class="p">),</span> <span class="p">),</span> <span class="nb">float</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xk</span><span class="p">)):</span>
        <span class="n">ei</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">*</span> <span class="n">ei</span>
        <span class="n">grad</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="p">((</span><span class="n">xk</span> <span class="o">+</span> <span class="n">d</span><span class="p">,)</span> <span class="o">+</span> <span class="n">args</span><span class="p">))</span> <span class="o">-</span> <span class="n">f0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">ei</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">grad</span>


<span class="k">class</span> <span class="nc">PairwiseKernel</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper for kernels in sklearn.metrics.pairwise.</span>

<span class="sd">    A thin wrapper around the functionality of the kernels in</span>
<span class="sd">    sklearn.metrics.pairwise.</span>

<span class="sd">    Note: Evaluation of eval_gradient is not analytic but numeric and all</span>
<span class="sd">          kernels support only isotropic distances. The parameter gamma is</span>
<span class="sd">          considered to be a hyperparameter and may be optimized. The other</span>
<span class="sd">          kernel parameters are set directly at initialization and are kept</span>
<span class="sd">          fixed.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gamma : float &gt;= 0, default: 1.0</span>
<span class="sd">        Parameter gamma of the pairwise kernel specified by metric</span>

<span class="sd">    gamma_bounds : pair of floats &gt;= 0, default: (1e-5, 1e5)</span>
<span class="sd">        The lower and upper bound on gamma</span>

<span class="sd">    metric : string, or callable, default: &quot;linear&quot;</span>
<span class="sd">        The metric to use when calculating kernel between instances in a</span>
<span class="sd">        feature array. If metric is a string, it must be one of the metrics</span>
<span class="sd">        in pairwise.PAIRWISE_KERNEL_FUNCTIONS.</span>
<span class="sd">        If metric is &quot;precomputed&quot;, X is assumed to be a kernel matrix.</span>
<span class="sd">        Alternatively, if metric is a callable function, it is called on each</span>
<span class="sd">        pair of instances (rows) and the resulting value recorded. The callable</span>
<span class="sd">        should take two arrays from X as input and return a value indicating</span>
<span class="sd">        the distance between them.</span>

<span class="sd">    pairwise_kernels_kwargs : dict, default: None</span>
<span class="sd">        All entries of this dict (if any) are passed as keyword arguments to</span>
<span class="sd">        the pairwise kernel function.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">gamma_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e5</span><span class="p">),</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span>
                 <span class="n">pairwise_kernels_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma_bounds</span> <span class="o">=</span> <span class="n">gamma_bounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pairwise_kernels_kwargs</span> <span class="o">=</span> <span class="n">pairwise_kernels_kwargs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">hyperparameter_gamma</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Hyperparameter</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="s2">&quot;numeric&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma_bounds</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the kernel k(X, Y) and optionally its gradient.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Y : array, shape (n_samples_Y, n_features), (optional, default=None)</span>
<span class="sd">            Right argument of the returned kernel k(X, Y). If None, k(X, X)</span>
<span class="sd">            if evaluated instead.</span>

<span class="sd">        eval_gradient : bool (optional, default=False)</span>
<span class="sd">            Determines whether the gradient with respect to the kernel</span>
<span class="sd">            hyperparameter is determined. Only supported when Y is None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K : array, shape (n_samples_X, n_samples_Y)</span>
<span class="sd">            Kernel k(X, Y)</span>

<span class="sd">        K_gradient : array (opt.), shape (n_samples_X, n_samples_X, n_dims)</span>
<span class="sd">            The gradient of the kernel k(X, X) with respect to the</span>
<span class="sd">            hyperparameter of the kernel. Only returned when eval_gradient</span>
<span class="sd">            is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pairwise_kernels_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise_kernels_kwargs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise_kernels_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pairwise_kernels_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">pairwise_kernels</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
                             <span class="n">filter_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                             <span class="o">**</span><span class="n">pairwise_kernels_kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparameter_gamma</span><span class="o">.</span><span class="n">fixed</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># approximate gradient numerically</span>
                <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">gamma</span><span class="p">):</span>  <span class="c1"># helper function</span>
                    <span class="k">return</span> <span class="n">pairwise_kernels</span><span class="p">(</span>
                        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">gamma</span><span class="p">),</span>
                        <span class="n">filter_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">pairwise_kernels_kwargs</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">K</span><span class="p">,</span> <span class="n">_approx_fprime</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span> <span class="nf">diag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the diagonal of the kernel k(X, X).</span>

<span class="sd">        The result of this method is identical to np.diag(self(X)); however,</span>
<span class="sd">        it can be evaluated more efficiently since only the diagonal is</span>
<span class="sd">        evaluated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape (n_samples_X, n_features)</span>
<span class="sd">            Left argument of the returned kernel k(X, Y)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        K_diag : array, shape (n_samples_X,)</span>
<span class="sd">            Diagonal of kernel k(X, X)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We have to fall back to slow way of computing diagonal</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">is_stationary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns whether the kernel is stationary. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;rbf&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{0}</span><span class="s2">(gamma=</span><span class="si">{1}</span><span class="s2">, metric=</span><span class="si">{2}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="p">)</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015-2019, Marius Lindauer, Matthias Feurer, Katharina Eggensperger, Joshua Marben, Andr Biedenkapp, Aaron Klein, Stefan Falkner and Frank Hutter

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>