{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Quadratic Function\n\nAn example of applying SMAC to optimize a quadratic function.\n\nWe use the black-box facade because it is designed for black-box function optimization.\nThe black-box facade uses a :term:`Gaussian Process<GP>` as its surrogate model.\nThe facade works best on a numerical hyperparameter configuration space and should not\nbe applied to problems with large evaluation budgets (up to 1000 evaluations).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom ConfigSpace import Configuration, ConfigurationSpace, Float\nfrom matplotlib import pyplot as plt\n\nfrom smac import HyperparameterOptimizationFacade as HPOFacade\nfrom smac import RunHistory, Scenario\n\n__copyright__ = \"Copyright 2021, AutoML.org Freiburg-Hannover\"\n__license__ = \"3-clause BSD\"\n\n\nclass QuadraticFunction:\n    @property\n    def configspace(self) -> ConfigurationSpace:\n        cs = ConfigurationSpace(seed=0)\n        x = Float(\"x\", (-5, 5), default=-5)\n        cs.add_hyperparameters([x])\n\n        return cs\n\n    def train(self, config: Configuration, seed: int = 0) -> float:\n        \"\"\"Returns the y value of a quadratic function with a minimum we know to be at x=0.\"\"\"\n        x = config[\"x\"]\n        return x**2\n\n\ndef plot(runhistory: RunHistory, incumbent: Configuration) -> None:\n    plt.figure()\n\n    # Plot ground truth\n    x = list(np.linspace(-5, 5, 100))\n    y = [xi * xi for xi in x]\n    plt.plot(x, y)\n\n    # Plot all trials\n    for k, v in runhistory.items():\n        config = runhistory.get_config(k.config_id)\n        x = config[\"x\"]\n        y = v.cost  # type: ignore\n        plt.scatter(x, y, c=\"blue\", alpha=0.1, zorder=9999, marker=\"o\")\n\n    # Plot incumbent\n    plt.scatter(incumbent[\"x\"], incumbent[\"x\"] * incumbent[\"x\"], c=\"red\", zorder=10000, marker=\"x\")\n\n    plt.show()\n\n\nif __name__ == \"__main__\":\n    model = QuadraticFunction()\n\n    # Scenario object specifying the optimization \"environment\"\n    scenario = Scenario(model.configspace, deterministic=True, n_trials=100)\n\n    # Now we use SMAC to find the best hyperparameters\n    smac = HPOFacade(\n        scenario,\n        model.train,  # We pass the target function here\n        overwrite=True,  # Overrides any previous results that are found that are inconsistent with the meta-data\n    )\n\n    incumbent = smac.optimize()\n\n    # Get cost of default configuration\n    default_cost = smac.validate(model.configspace.get_default_configuration())\n    print(f\"Default cost: {default_cost}\")\n\n    # Let's calculate the cost of the incumbent\n    incumbent_cost = smac.validate(incumbent)\n    print(f\"Incumbent cost: {incumbent_cost}\")\n\n    # Let's plot it too\n    plot(smac.runhistory, incumbent)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}