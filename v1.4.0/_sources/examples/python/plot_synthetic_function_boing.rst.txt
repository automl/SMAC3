
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/python/plot_synthetic_function_boing.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_python_plot_synthetic_function_boing.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_python_plot_synthetic_function_boing.py:


Synthetic Function with BOinG as optimizer
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

An example of applying SMAC with BO inside Grove (BOinG) to optimize a
synthetic function (2d rosenbrock function).

BOinG optimizer requires a SMAC4BOING wrapper to optimize the target algorithm. It is a two stage BO algorithm.
In the first stage, BOinG constructs an RF to capture the global loss landscape. Then in the second stage, it only
optimizes inside a subregion near the candidate suggested by the RF model with a GP model to focus only on the most
promising region.

.. GENERATED FROM PYTHON SOURCE LINES 13-75




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2022-07-14_08:14:14_884608
    Default Value: 16916.00
    Optimizing! Depending on your machine, this might take a few minutes.
    INFO:smac.facade.smac_boing_facade.SMAC4BOING:Optimizing a deterministic scenario for quality without a tuner timeout - will make SMAC deterministic and only evaluate one configuration per iteration!
    INFO:smac.initial_design.sobol_design.SobolDesign:Running initial design for 5 configurations
    INFO:smac.facade.smac_boing_facade.SMAC4BOING:<class 'smac.facade.smac_boing_facade.SMAC4BOING'>
    INFO:smac.optimizer.smbo.SMBO:Running initial design
    INFO:smac.intensification.intensification.Intensifier:First run, no incumbent provided; challenger is assumed to be the incumbent
    INFO:smac.intensification.intensification.Intensifier:First run, no incumbent provided; challenger is assumed to be the incumbent
    INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 11306.5205
    INFO:smac.intensification.intensification.Intensifier:Challenger (13.7271) is better than incumbent (11306.5205) on 1 runs.
    INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:
    INFO:smac.intensification.intensification.Intensifier:  x0 : -3.6466374900192022 -> 0.21284371614456177
    INFO:smac.intensification.intensification.Intensifier:  x1 : 2.6749102026224136 -> -0.31674057245254517
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:136: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.
    torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.
    X = torch.triangular_solve(B, A).solution
    should be replaced with
    X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2189.)
      res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    INFO:smac.intensification.intensification.Intensifier:Challenger (13.0827) is better than incumbent (13.7271) on 1 runs.
    INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:
    INFO:smac.intensification.intensification.Intensifier:  x0 : 0.21284371614456177 -> -2.609301344352092
    INFO:smac.intensification.intensification.Intensifier:  x1 : -0.31674057245254517 -> 6.784860015200639
    INFO:smac.intensification.intensification.Intensifier:Challenger (0.2843) is better than incumbent (13.0827) on 1 runs.
    INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:
    INFO:smac.intensification.intensification.Intensifier:  x0 : -2.609301344352092 -> 0.8172906201107062
    INFO:smac.intensification.intensification.Intensifier:  x1 : 6.784860015200639 -> 0.7180555424372059
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    /opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/gpytorch/models/exact_gp.py:273: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
      warnings.warn(
    INFO:smac.stats.stats.Stats:---------------------STATISTICS---------------------
    INFO:smac.stats.stats.Stats:Incumbent changed: 3
    INFO:smac.stats.stats.Stats:Submitted target algorithm runs: 20 / 20.0
    INFO:smac.stats.stats.Stats:Finished target algorithm runs: 20 / 20.0
    INFO:smac.stats.stats.Stats:Configurations: 20
    INFO:smac.stats.stats.Stats:Used wallclock time: 21.15 / inf sec 
    INFO:smac.stats.stats.Stats:Used target algorithm runtime: 0.00 / inf sec
    INFO:smac.stats.stats.Stats:----------------------------------------------------
    INFO:smac.facade.smac_boing_facade.SMAC4BOING:Final Incumbent: Configuration(values={
      'x0': 0.8172906201107062,
      'x1': 0.7180555424372059,
    })

    INFO:smac.facade.smac_boing_facade.SMAC4BOING:Estimated cost of incumbent: 0.2843






|

.. code-block:: default


    import logging

    import numpy as np
    from ConfigSpace import ConfigurationSpace
    from ConfigSpace.hyperparameters import UniformFloatHyperparameter

    from smac.facade.smac_boing_facade import SMAC4BOING

    # Import SMAC-utilities
    from smac.scenario.scenario import Scenario


    def rosenbrock_2d(x):
        """The 2 dimensional Rosenbrock function as a toy model
        The Rosenbrock function is well know in the optimization community and
        often serves as a toy problem. It can be defined for arbitrary
        dimensions. The minimium is always at x_i = 1 with a function value of
        zero. All input parameters are continuous. The search domain for
        all x's is the interval [-5, 10].
        """
        x1 = x["x0"]
        x2 = x["x1"]

        val = 100.0 * (x2 - x1**2.0) ** 2.0 + (1 - x1) ** 2.0
        return val


    if __name__ == "__main__":
        logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output

        # Build Configuration Space which defines all parameters and their ranges
        cs = ConfigurationSpace()
        x0 = UniformFloatHyperparameter("x0", -5, 10, default_value=-3)
        x1 = UniformFloatHyperparameter("x1", -5, 10, default_value=-4)
        cs.add_hyperparameters([x0, x1])
        # Scenario object
        scenario = Scenario(
            {
                "run_obj": "quality",  # we optimize quality (alternatively runtime)
                "runcount-limit": 20,
                # max. number of function evaluations; for this example set to a low number
                "cs": cs,  # configuration space
                "deterministic": "true",
            }
        )

        # Example call of the function
        # It returns: Status, Cost, Runtime, Additional Infos
        def_value = rosenbrock_2d(cs.get_default_configuration())
        print("Default Value: %.2f" % def_value)

        # Optimize, using a SMAC-object
        print("Optimizing! Depending on your machine, this might take a few minutes.")

        smac = SMAC4BOING(
            scenario=scenario,
            rng=np.random.RandomState(42),
            tae_runner=rosenbrock_2d,
        )

        smac.optimize()


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  21.157 seconds)


.. _sphx_glr_download_examples_python_plot_synthetic_function_boing.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_synthetic_function_boing.py <plot_synthetic_function_boing.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_synthetic_function_boing.ipynb <plot_synthetic_function_boing.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
