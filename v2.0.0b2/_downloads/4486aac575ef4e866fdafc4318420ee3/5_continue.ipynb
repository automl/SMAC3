{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Continue an Optimization\n\nSMAC can also be continued. In this example, an optimization of a simple quadratic\nfunction is continued. We use a custom callback, to artificially stop the first optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n\nfrom ConfigSpace import Configuration, ConfigurationSpace, Float\n\nfrom smac import Callback\nfrom smac import HyperparameterOptimizationFacade as HPOFacade\nfrom smac import Scenario\nfrom smac.main.smbo import SMBO\nfrom smac.runhistory import TrialInfo, TrialValue\n\n__copyright__ = \"Copyright 2021, AutoML.org Freiburg-Hannover\"\n__license__ = \"3-clause BSD\"\n\n\nclass StopCallback(Callback):\n    def __init__(self, stop_after: int):\n        self._stop_after = stop_after\n\n    def on_tell_end(self, smbo: SMBO, info: TrialInfo, value: TrialValue) -> bool | None:\n        \"\"\"Called after the stats are updated and the trial is added to the runhistory. Optionally, returns false\n        to gracefully stop the optimization.\n        \"\"\"\n        if smbo.runhistory.finished == self._stop_after:\n            return False\n\n        return None\n\n\nclass QuadraticFunction:\n    @property\n    def configspace(self) -> ConfigurationSpace:\n        cs = ConfigurationSpace(seed=0)\n        x = Float(\"x\", (-5, 5), default=-5)\n        cs.add_hyperparameters([x])\n\n        return cs\n\n    def train(self, config: Configuration, seed: int = 0) -> float:\n        \"\"\"Returns the y value of a quadratic function with a minimum at x=0.\"\"\"\n        x = config[\"x\"]\n        return x * x\n\n\nif __name__ == \"__main__\":\n    model = QuadraticFunction()\n\n    # Scenario object specifying the optimization \"environment\"\n    scenario = Scenario(model.configspace, deterministic=True, n_trials=50)\n    stop_after = 10\n\n    # Now we use SMAC to find the best hyperparameters\n    smac = HPOFacade(\n        scenario,\n        model.train,  # We pass the target function here\n        callbacks=[StopCallback(stop_after=stop_after)],\n        overwrite=True,  # Overrides any previous results that are found that are inconsistent with the meta-data\n    )\n\n    incumbent = smac.optimize()\n    assert smac.runhistory.finished == stop_after\n\n    # Now, we want to continue the optimization\n    # Make sure, we don't overwrite the last run\n    smac2 = HPOFacade(\n        scenario,\n        model.train,\n        overwrite=False,\n    )\n\n    # Check whether we get the same incumbent\n    assert smac.intensifier.get_incumbent() == smac2.intensifier.get_incumbent()\n    assert smac2.runhistory.finished == stop_after\n\n    # And now we finish the optimization\n    incumbent2 = smac2.optimize()\n\n    default_cost = smac.validate(model.configspace.get_default_configuration())\n    print(f\"Default cost: {default_cost}\")\n\n    incumbent_cost = smac.validate(incumbent)\n    print(f\"Incumbent cost of first run: {incumbent_cost}\")\n\n    incumbent_cost = smac2.validate(incumbent2)\n    print(f\"Incumbent cost of continued run: {incumbent_cost}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}