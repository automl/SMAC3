
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>smac.model.gaussian_process.kernels.boing &#8212; SMAC3 Documentation 2.0.0 documentation</title>
    
  <link href="../../../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../../../_static/css/index.ac9c05f7c49ca1e1f876c6e36360ea26.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sg_gallery-rendered-html.css" />
    
  <link rel="preload" as="script" href="../../../../../_static/js/index.9ea38e314b9e6d9dab77.js">

    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
  <a class="navbar-brand" href="../../../../../index.html">
    <img src="../../../../../_static/logo.png" class="logo" alt="logo">
  </a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/https://github.com/automl/SMAC3" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/automl_org?lang=de" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search align-items-center" action="../../../../../search.html" method="get"
style="width: 100%;">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>

      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><h4 class="mt-0 mb-0"><a href="../../../../../index.html">SMAC3 Documentation</a></h4>
<div class="mb-3">v2.0.0</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../package_overview.html">
   Package Overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../getting_started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../minimal_example.html">
   Minimal Example
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../../../examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../examples/1_basics/index.html">
     Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../examples/2_multi_fidelity/index.html">
     Multi-Fidelity and Multi-Instances
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../examples/3_multi_objective/index.html">
     Multi-Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../examples/4_commandline/index.html">
     Commandline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../../../advanced_usage/index.html">
   Advanced Usage
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../advanced_usage/resumption.html">
     Resumption
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../advanced_usage/callbacks.html">
     Callbacks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../../../api.html">
   API References
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.facade.html">
     smac.facade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.main.html">
     smac.main
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.model.html">
     smac.model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.acquisition.html">
     smac.acquisition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.intensification.html">
     smac.intensification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.initial_design.html">
     smac.initial_design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.random_design.html">
     smac.random_design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.runner.html">
     smac.runner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.runhistory.html">
     smac.runhistory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.multi_objective.html">
     smac.multi_objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.configspace.html">
     smac.configspace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.utils.html">
     smac.utils
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.scenario.html">
     smac.scenario
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.constants.html">
     smac.constants
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../../../api/smac.callback.html">
     smac.callback
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../faq.html">
   F.A.Q.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../../../license.html">
   License
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for smac.model.gaussian_process.kernels.boing</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">import</span> <span class="nn">gpytorch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">gpytorch</span> <span class="kn">import</span> <span class="n">settings</span>
<span class="kn">from</span> <span class="nn">gpytorch.kernels</span> <span class="kn">import</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">MaternKernel</span><span class="p">,</span> <span class="n">ProductKernel</span><span class="p">,</span> <span class="n">ScaleKernel</span>
<span class="kn">from</span> <span class="nn">gpytorch.lazy</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">DiagLazyTensor</span><span class="p">,</span>
    <span class="n">MatmulLazyTensor</span><span class="p">,</span>
    <span class="n">PsdSumLazyTensor</span><span class="p">,</span>
    <span class="n">RootLazyTensor</span><span class="p">,</span>
    <span class="n">delazify</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">gpytorch.likelihoods</span> <span class="kn">import</span> <span class="n">GaussianLikelihood</span>
<span class="kn">from</span> <span class="nn">gpytorch.means.mean</span> <span class="kn">import</span> <span class="n">Mean</span>
<span class="kn">from</span> <span class="nn">gpytorch.utils.cholesky</span> <span class="kn">import</span> <span class="n">psd_safe_cholesky</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">Kernel</span> <span class="k">as</span> <span class="n">SKLKernels</span>

<span class="kn">from</span> <span class="nn">smac.model.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">ConstantKernel</span><span class="p">,</span> <span class="n">WhiteKernel</span>


<div class="viewcode-block" id="MixedKernel"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.MixedKernel">[docs]</a><span class="k">class</span> <span class="nc">MixedKernel</span><span class="p">(</span><span class="n">ProductKernel</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A special form of ProductKernel. It is composed of a cont_kernel and a cat_kernel that work with continuous and</span>
<span class="sd">    categorical parameters, respectively. Its forward pass allows an additional parameter to determine if only</span>
<span class="sd">    cont_kernel is applied to the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cont_kernel</span><span class="p">:</span> <span class="n">Kernel</span><span class="p">,</span> <span class="n">cat_kernel</span><span class="p">:</span> <span class="n">Kernel</span><span class="p">):</span>
        <span class="n">kernels</span> <span class="o">=</span> <span class="n">cont_kernel</span><span class="o">.</span><span class="n">kernels</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cont_kernel</span><span class="p">,</span> <span class="n">ProductKernel</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">cont_kernel</span><span class="p">]</span>
        <span class="n">kernels</span> <span class="o">+=</span> <span class="n">cat_kernel</span><span class="o">.</span><span class="n">kernels</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cat_kernel</span><span class="p">,</span> <span class="n">ProductKernel</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">cat_kernel</span><span class="p">]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">kernels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cont_kernel</span> <span class="o">=</span> <span class="n">cont_kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_kernel</span> <span class="o">=</span> <span class="n">cat_kernel</span>

<div class="viewcode-block" id="MixedKernel.get_meta"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.MixedKernel.get_meta">[docs]</a>    <span class="k">def</span> <span class="nf">get_meta</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Returns the meta data of the created object.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
        <span class="p">}</span></div>

<div class="viewcode-block" id="MixedKernel.forward"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.MixedKernel.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">diag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">cont_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">lazy</span><span class="o">.</span><span class="n">LazyTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute kernel values, if cont_only is True, then the categorical kernel is omitted&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">cont_only</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">diag</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cont_kernel</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">diag</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="construct_gp_kernel"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.construct_gp_kernel">[docs]</a><span class="k">def</span> <span class="nf">construct_gp_kernel</span><span class="p">(</span>
    <span class="n">kernel_kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">cont_dims</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">cat_dims</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Kernel</span> <span class="o">|</span> <span class="n">SKLKernels</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Construct a GP kernel with the given kernel init argument, the cont_dims, and cat_dims of the problem. Since the</span>
<span class="sd">    subspace might not have the same number of dimensions as the global search space.</span>
<span class="sd">    We need to reconstruct the kernel every time when a new subspace is generated.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kernel_kwargs: Dict[str, Any]</span>
<span class="sd">        kernel kwargs. Arguments to initialize the kernels. It needs to contain the following items:</span>
<span class="sd">            cont_kernel: type of continuous kernels</span>
<span class="sd">            cont_kernel_kwargs: additional arguments for continuous kernels, for instance, length constraints and prior</span>
<span class="sd">            cat_kernel: type of categorical kernels</span>
<span class="sd">            cat_kernel_kwargs: additional arguments for categorical kernels, for instance, length constraints and prior</span>
<span class="sd">            scale_kernel: type of scale kernels</span>
<span class="sd">            scale_kernel_kwargs: additional arguments for scale kernels,  for instance, length constraints and prior</span>
<span class="sd">    cont_dims: np.ndarray</span>
<span class="sd">        dimensions of continuous hyperparameters</span>
<span class="sd">    cat_dims: np.ndarray</span>
<span class="sd">        dimensions of categorical hyperparameters</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    kernel: Kernel | SKLKernels</span>
<span class="sd">        constructed kernels</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cont_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cont_kernel_class</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cont_kernel&quot;</span><span class="p">,</span> <span class="n">MaternKernel</span><span class="p">)</span>
        <span class="n">cont_kernel_kwargs</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cont_kernel_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">cont_kernel</span> <span class="o">=</span> <span class="n">cont_kernel_class</span><span class="p">(</span>
            <span class="n">ard_num_dims</span><span class="o">=</span><span class="n">cont_dims</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">active_dims</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">cont_dims</span><span class="p">),</span> <span class="o">**</span><span class="n">cont_kernel_kwargs</span>
        <span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cat_kernel_class</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cat_kernel&quot;</span><span class="p">,</span> <span class="n">MaternKernel</span><span class="p">)</span>
        <span class="n">cat_kernel_kwargs</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cat_kernel_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">cat_kernel</span> <span class="o">=</span> <span class="n">cat_kernel_class</span><span class="p">(</span>
            <span class="n">ard_num_dims</span><span class="o">=</span><span class="n">cat_dims</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">active_dims</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">),</span> <span class="o">**</span><span class="n">cat_kernel_kwargs</span>
        <span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cont_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cont_kernel</span><span class="p">,</span> <span class="n">SKLKernels</span><span class="p">):</span>
            <span class="n">base_kernel</span> <span class="o">=</span> <span class="n">cont_kernel</span> <span class="o">*</span> <span class="n">cat_kernel</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">base_kernel</span> <span class="o">=</span> <span class="n">MixedKernel</span><span class="p">(</span><span class="n">cont_kernel</span><span class="o">=</span><span class="n">cont_kernel</span><span class="p">,</span> <span class="n">cat_kernel</span><span class="o">=</span><span class="n">cat_kernel</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">cont_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">base_kernel</span> <span class="o">=</span> <span class="n">cont_kernel</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">cont_dims</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">base_kernel</span> <span class="o">=</span> <span class="n">cat_kernel</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Either cont_dims or cat_dims must exist!&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">base_kernel</span><span class="p">,</span> <span class="n">SKLKernels</span><span class="p">):</span>
        <span class="n">scale_kernel_class</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale_kernel&quot;</span><span class="p">,</span> <span class="n">ConstantKernel</span><span class="p">)</span>
        <span class="n">scale_kernel_kwargs</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale_kernel_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">scale_kernel</span> <span class="o">=</span> <span class="n">scale_kernel_class</span><span class="p">(</span><span class="o">**</span><span class="n">scale_kernel_kwargs</span><span class="p">)</span>

        <span class="n">noise_kernel_class</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;noise_kernel&quot;</span><span class="p">,</span> <span class="n">WhiteKernel</span><span class="p">)</span>
        <span class="n">noise_kernel_kwargs</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;noise_kernel_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">noise_kernel</span> <span class="o">=</span> <span class="n">noise_kernel_class</span><span class="p">(</span><span class="o">**</span><span class="n">noise_kernel_kwargs</span><span class="p">)</span>

        <span class="n">gp_kernel</span> <span class="o">=</span> <span class="n">scale_kernel</span> <span class="o">*</span> <span class="n">base_kernel</span> <span class="o">+</span> <span class="n">noise_kernel</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scale_kernel_class</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale_kernel&quot;</span><span class="p">,</span> <span class="n">ScaleKernel</span><span class="p">)</span>
        <span class="n">scale_kernel_kwargs</span> <span class="o">=</span> <span class="n">kernel_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale_kernel_kwargs&quot;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="n">gp_kernel</span> <span class="o">=</span> <span class="n">scale_kernel_class</span><span class="p">(</span><span class="n">base_kernel</span><span class="o">=</span><span class="n">base_kernel</span><span class="p">,</span> <span class="o">**</span><span class="n">scale_kernel_kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gp_kernel</span></div>


<div class="viewcode-block" id="FITCKernel"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.FITCKernel">[docs]</a><span class="k">class</span> <span class="nc">FITCKernel</span><span class="p">(</span><span class="n">Kernel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">base_kernel</span><span class="p">:</span> <span class="n">Kernel</span><span class="p">,</span>
        <span class="n">X_inducing</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">likelihood</span><span class="p">:</span> <span class="n">GaussianLikelihood</span><span class="p">,</span>
        <span class="n">X_out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">y_out</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">active_dims</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A reimplementation of FITC Kernel that computes the posterior explicitly for globally augmented local GP.</span>
<span class="sd">        This should work exactly the same as a gpytorch.kernel.InducingPointKernel.</span>
<span class="sd">         However, it takes much less time when combined with LGPGA.</span>
<span class="sd">         References: Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. Advances in</span>
<span class="sd">         Neural Information Processing Systems 18, Cambridge, Massachusetts, 2006. The MIT Press.</span>
<span class="sd">         https://papers.nips.cc/paper/2005/hash/4491777b1aa8b5b32c2e8666dbe1a495-Abstract.html</span>

<span class="sd">        Mean value is computed with:</span>
<span class="sd">        \mathbf{\mu_{l&#39;}}  = \mathbf{K_{l&#39;,u} \Sigma K_{u,1} \Lambda}^{-1}\mathbf{y_g} \label{eq:mean_sgp}</span>
<span class="sd">        and variance value:</span>
<span class="sd">        \mathbf{\sigma}^2_{l&#39;} = \mathbf{K_{l&#39;,l&#39;}} - \mathbf{Q_{l&#39;, l&#39;} + \mathbf{K_{l&#39;, u}\Sigma K_{u, l&#39;}}}</span>
<span class="sd">        \mathbf{\Sigma} = (\mathbf{K_{u,u}} + \mathbf{K_{u, g} \Lambda}^{-1}\mathbf{K_{g,u}})^{-1}</span>
<span class="sd">        \mathbf{\Lambda} = diag[\mathbf{K_{g,g}-Q_{g,g}} + \sigma^2_{noise}\idenmat]</span>
<span class="sd">        ----------</span>
<span class="sd">        base_kernel: Kernel</span>
<span class="sd">            base kernel function</span>
<span class="sd">        X_inducing: torch.Tensor (N_inducing, D)</span>
<span class="sd">            inducing points, a torch tensor with shape (N_inducing, D), N_inducing is the number of the inducing points</span>
<span class="sd">        likelihood: GaussianLikelihood</span>
<span class="sd">            GP likelihood</span>
<span class="sd">        X_out: torch.Tensor (N_out,D)</span>
<span class="sd">            data features outside the subregion, it needs to be of size (N_out, D), N_out is the number of points</span>
<span class="sd">            outside the subspace</span>
<span class="sd">        y_out: torch.Tensor</span>
<span class="sd">            data observations outside the subregion</span>
<span class="sd">        active_dims: Tuple[int] | None = None</span>
<span class="sd">            Set this if you want to compute the covariance of only a few input dimensions. The ints</span>
<span class="sd">            corresponds to the indices of the dimensions. Default: `None`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FITCKernel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">active_dims</span><span class="o">=</span><span class="n">active_dims</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_lengthscale</span> <span class="o">=</span> <span class="n">base_kernel</span><span class="o">.</span><span class="n">has_lengthscale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span> <span class="o">=</span> <span class="n">base_kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span>

        <span class="k">if</span> <span class="n">X_inducing</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X_inducing</span> <span class="o">=</span> <span class="n">X_inducing</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_out</span> <span class="o">=</span> <span class="n">X_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span> <span class="o">=</span> <span class="n">y_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;X_inducing&quot;</span><span class="p">,</span> <span class="n">parameter</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">X_inducing</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_clear_cache</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_kernel_mat&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_mat</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_inducing_sigma&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_poster_mean_mat&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_poster_mean_mat</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_train_cached_k_u1&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_k_u1</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_train_cached_lambda_diag_inv&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_lambda_diag_inv</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_train_cached_posterior_mean&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_posterior_mean</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_kernel_inv_root&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_inv_root</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_inducing_mat</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes inducing matrix, K(X_inducing, X_inducing)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_inducing, N_inducing)</span>
<span class="sd">            K(X_inducing, X_inducing)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_kernel_mat&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_mat</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_mat</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_inducing_inv_root</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the inverse of the inducing matrix: K_inv(X_inducing, X_inducing) = K(X_inducing, X_inducing)^(-1)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_inducing, N_inducing)</span>
<span class="sd">            K_inv(X_inducing, X_inducing)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_kernel_inv_root&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_inv_root</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chol</span> <span class="o">=</span> <span class="n">psd_safe_cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inducing_mat</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">jitter</span><span class="o">=</span><span class="n">settings</span><span class="o">.</span><span class="n">cholesky_jitter</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>
            <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">chol</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">chol</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">chol</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">inv_root</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">(</span><span class="n">eye</span><span class="p">,</span> <span class="n">chol</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">res</span> <span class="o">=</span> <span class="n">inv_root</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_inv_root</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_k_u1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the covariance matrix between the X_inducing and X_out : K(X_inducing, X_out)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_inducing, N_out)</span>
<span class="sd">            K(X_inducing, X_out)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_k_u1&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_k_u1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_out</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_k_u1</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_k_u1</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_lambda_diag_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the inverse of lambda matrix, it is computed by</span>
<span class="sd">        \Lambda = diag[\mathbf{K_{X_out,X_out}-Q_{X_out,X_out}} + \sigma^2_{noise}\idenmat] and</span>
<span class="sd">        Q{X_out, X_out} = K(X_out, X_inducing) K^{-1}(X_inducing,X_inducing) K(X_inducing, X_out)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_out, N_out)</span>
<span class="sd">            inverse of the diagonal matrix lambda</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_lambda_diag_inv&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_lambda_diag_inv</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">diag_k11</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_out</span><span class="p">,</span> <span class="n">diag</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

            <span class="n">diag_q11</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="n">RootLazyTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_k_u1</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inducing_inv_root</span><span class="p">)))</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>

            <span class="c1"># Diagonal correction for predictive posterior</span>
            <span class="n">correction</span> <span class="o">=</span> <span class="p">(</span><span class="n">diag_k11</span> <span class="o">-</span> <span class="n">diag_q11</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

            <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">_shaped_noise_covar</span><span class="p">(</span><span class="n">correction</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>

            <span class="n">res</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="n">DiagLazyTensor</span><span class="p">((</span><span class="n">correction</span> <span class="o">+</span> <span class="n">sigma</span><span class="p">)</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">()))</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_lambda_diag_inv</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_lambda_diag_inv</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_inducing_sigma</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the inverse of lambda matrix, it is computed by</span>
<span class="sd">        \mathbf{\Sigma} = (\mathbf{K_{X_inducing,X_inducing}} +</span>
<span class="sd">         \mathbf{K_{X_inducing, X_out} \Lambda}^{-1}\mathbf{K_{X_out,X_inducing}})</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_inducing, N_inducing)</span>
<span class="sd">            \Sigma</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_inducing_sigma&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k_u1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_k_u1</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">PsdSumLazyTensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_inducing_mat</span><span class="p">,</span>
                <span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="n">k_u1</span><span class="p">,</span> <span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_lambda_diag_inv</span><span class="p">,</span> <span class="n">k_u1</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))),</span>
            <span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>

            <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_inducing_sigma_inv_root</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Inverse of Sigma matrix:</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_inducing, N_inducing)</span>
<span class="sd">            \Sigma ^{-1}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_inducing_sigma_inv_root&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma_inv_root</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chol</span> <span class="o">=</span> <span class="n">psd_safe_cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_inducing_sigma</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">jitter</span><span class="o">=</span><span class="n">settings</span><span class="o">.</span><span class="n">cholesky_jitter</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>

            <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">chol</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">chol</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">chol</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">inv_root</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">(</span><span class="n">eye</span><span class="p">,</span> <span class="n">chol</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">inv_root</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma_inv_root</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_poster_mean_mat</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;A cached value for computing the posterior mean of a sparse kernel it is defined by</span>
<span class="sd">        \Sigma K_{u, 1} \Lambda}^{-1}\mathbf{y_out}</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor (N_inducing, 1)</span>
<span class="sd">            cached posterior mean</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_poster_mean_mat&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_poster_mean_mat</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inducing_sigma_inv_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inducing_sigma_inv_root</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">RootLazyTensor</span><span class="p">(</span><span class="n">inducing_sigma_inv_root</span><span class="p">)</span>

            <span class="n">k_u1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_k_u1</span>
            <span class="n">lambda_diag_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lambda_diag_inv</span>

            <span class="n">res_mat</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="n">k_u1</span><span class="p">,</span> <span class="n">lambda_diag_inv</span><span class="p">)))</span>

            <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">res_mat</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_cached_poster_mean_mat</span> <span class="o">=</span> <span class="n">res</span>  <span class="c1"># type: torch.Tensor</span>
            <span class="k">return</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">_get_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">lazy</span><span class="o">.</span><span class="n">LazyTensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Compute the posterior covariance matrix of a sparse kernel explicitly</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x1: torch.Tensor(N_x1, D)</span>
<span class="sd">            first input of the FITC kernel</span>
<span class="sd">        x2: torch.Tensor(N_x2, D)</span>
<span class="sd">            second input of the FITC kernel</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: Optional[torch.Tensor (N_x1, 1), PsdSumLazyTensor]</span>
<span class="sd">            a cached value for computing the posterior mean, it</span>
<span class="sd">            is defined by  \Sigma K_{u, 1} \Lambda}^{-1}\mathbf{y_out}</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">k_x1x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
        <span class="n">k_x1u</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">))</span>
        <span class="n">inducing_inv_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inducing_inv_root</span>
        <span class="n">inducing_sigma_inv_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inducing_sigma_inv_root</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
            <span class="n">q_x1x2</span> <span class="o">=</span> <span class="n">RootLazyTensor</span><span class="p">(</span><span class="n">k_x1u</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inducing_inv_root</span><span class="p">))</span>

            <span class="n">s_x1x2</span> <span class="o">=</span> <span class="n">RootLazyTensor</span><span class="p">(</span><span class="n">k_x1u</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inducing_sigma_inv_root</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">k_x2u</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">))</span>
            <span class="n">q_x1x2</span> <span class="o">=</span> <span class="n">MatmulLazyTensor</span><span class="p">(</span>
                <span class="n">k_x1u</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inducing_inv_root</span><span class="p">),</span> <span class="n">k_x2u</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inducing_inv_root</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">s_x1x2</span> <span class="o">=</span> <span class="n">MatmulLazyTensor</span><span class="p">(</span>
                <span class="n">k_x1u</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inducing_sigma_inv_root</span><span class="p">),</span> <span class="n">k_x2u</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inducing_sigma_inv_root</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">covar</span> <span class="o">=</span> <span class="n">PsdSumLazyTensor</span><span class="p">(</span><span class="n">k_x1x2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">q_x1x2</span><span class="p">,</span> <span class="n">s_x1x2</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">k_iu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">)</span>
            <span class="n">sigma</span> <span class="o">=</span> <span class="n">RootLazyTensor</span><span class="p">(</span><span class="n">inducing_sigma_inv_root</span><span class="p">)</span>

            <span class="n">k_u1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_k_u1</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_train_cached_k_u1&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_k_u1</span>
            <span class="n">lambda_diag_inv</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_lambda_diag_inv</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_train_cached_lambda_diag_inv&quot;</span><span class="p">)</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lambda_diag_inv</span>
            <span class="p">)</span>

            <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
                <span class="n">delazify</span><span class="p">(</span><span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="n">k_iu</span><span class="p">,</span> <span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">MatmulLazyTensor</span><span class="p">(</span><span class="n">k_u1</span><span class="p">,</span> <span class="n">lambda_diag_inv</span><span class="p">)))),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_posterior_mean</span> <span class="o">=</span> <span class="n">mean</span>  <span class="c1"># type: torch.Tensor</span>
        <span class="k">return</span> <span class="n">covar</span>

<div class="viewcode-block" id="FITCKernel.posterior_mean"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.FITCKernel.posterior_mean">[docs]</a>    <span class="k">def</span> <span class="nf">posterior_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The posterior mean of the FITC kernel, will serve as the prior mean of the dense kernel.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        inputs: torch.Tensor(N_inputs, D)</span>
<span class="sd">            input of the FITC kernel</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: Torch.Tensor (N_inputs, 1)</span>
<span class="sd">            The posterior mean of the FITC Kernel</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_train_cached_posterior_mean&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_cached_posterior_mean</span>
        <span class="k">if</span> <span class="n">inputs</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">k_iu</span> <span class="o">=</span> <span class="n">delazify</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">,</span> <span class="n">cont_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="n">poster_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_poster_mean_mat</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">k_iu</span><span class="p">,</span> <span class="n">poster_mean</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span></div>

<div class="viewcode-block" id="FITCKernel.forward"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.FITCKernel.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">diag</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">gpytorch</span><span class="o">.</span><span class="n">lazy</span><span class="o">.</span><span class="n">LazyTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the kernel function&quot;&quot;&quot;</span>
        <span class="n">covar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_covariance</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;x1 should equal x2 in training mode&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">diag</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">covar</span><span class="o">.</span><span class="n">diag</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">covar</span></div>

<div class="viewcode-block" id="FITCKernel.num_outputs_per_input"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.FITCKernel.num_outputs_per_input">[docs]</a>    <span class="k">def</span> <span class="nf">num_outputs_per_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Number of outputs given the inputs</span>
<span class="sd">        if x1 is of size `n x d` and x2 is size `m x d`, then the size of the kernel</span>
<span class="sd">        will be `(n * num_outputs_per_input) x (m * num_outputs_per_input)`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x1: torch.Tensor</span>
<span class="sd">            the first input of the kernel</span>
<span class="sd">        x2: torch.Tensor</span>
<span class="sd">            the second input of the kernel</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: int</span>
<span class="sd">            for base kernels such as matern or RBF kernels, this value needs to be 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="o">.</span><span class="n">num_outputs_per_input</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;FITCKernel&quot;</span><span class="p">:</span>
        <span class="n">replace_inv_root</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">replace_kernel_mat</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">replace_k_u1</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">replace_lambda_diag_inv</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">replace_inducing_sigma</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">replace_inducing_sigma_inv_root</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">replace_poster_mean</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_kernel_inv_root&quot;</span><span class="p">):</span>
            <span class="n">replace_inv_root</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">kernel_inv_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_inv_root</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_kernel_mat&quot;</span><span class="p">):</span>
            <span class="n">replace_kernel_mat</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">kernel_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_kernel_mat</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_k_u1&quot;</span><span class="p">):</span>
            <span class="n">replace_k_u1</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">k_u1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_k_u1</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_lambda_diag_inv&quot;</span><span class="p">):</span>
            <span class="n">replace_lambda_diag_inv</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">lambda_diag_inv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_lambda_diag_inv</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_inducing_sigma&quot;</span><span class="p">):</span>
            <span class="n">replace_inducing_sigma</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">inducing_sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_inducing_sigma_inv_root&quot;</span><span class="p">):</span>
            <span class="n">replace_inducing_sigma_inv_root</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">inducing_sigma_inv_root</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_inducing_sigma_inv_root</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_cached_poster_mean_mat&quot;</span><span class="p">):</span>
            <span class="n">replace_poster_mean</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">poster_mean_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cached_poster_mean_mat</span>

        <span class="n">cp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span>
            <span class="n">base_kernel</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">base_kernel</span><span class="p">),</span>
            <span class="n">X_inducing</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_inducing</span><span class="p">),</span>
            <span class="n">X_out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">X_out</span><span class="p">,</span>
            <span class="n">y_out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_out</span><span class="p">,</span>
            <span class="n">likelihood</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">),</span>
            <span class="n">active_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">active_dims</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">replace_inv_root</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_kernel_inv_root</span> <span class="o">=</span> <span class="n">kernel_inv_root</span>

        <span class="k">if</span> <span class="n">replace_kernel_mat</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_kernel_mat</span> <span class="o">=</span> <span class="n">kernel_mat</span>

        <span class="k">if</span> <span class="n">replace_k_u1</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_k_u1</span> <span class="o">=</span> <span class="n">k_u1</span>

        <span class="k">if</span> <span class="n">replace_lambda_diag_inv</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_lambda_diag_inv</span> <span class="o">=</span> <span class="n">lambda_diag_inv</span>

        <span class="k">if</span> <span class="n">replace_inducing_sigma</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_inducing_sigma</span> <span class="o">=</span> <span class="n">inducing_sigma</span>

        <span class="k">if</span> <span class="n">replace_inducing_sigma_inv_root</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_inducing_sigma_inv_root</span> <span class="o">=</span> <span class="n">inducing_sigma_inv_root</span>

        <span class="k">if</span> <span class="n">replace_poster_mean</span><span class="p">:</span>
            <span class="n">cp</span><span class="o">.</span><span class="n">_cached_poster_mean_mat</span> <span class="o">=</span> <span class="n">poster_mean_mat</span>

        <span class="k">return</span> <span class="n">cp</span></div>


<div class="viewcode-block" id="FITCMean"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.FITCMean">[docs]</a><span class="k">class</span> <span class="nc">FITCMean</span><span class="p">(</span><span class="n">Mean</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">covar_module</span><span class="p">:</span> <span class="n">FITCKernel</span><span class="p">,</span> <span class="n">batch_shape</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Read the posterior mean value of the given fitc kernel and serve as a prior mean value for the</span>
<span class="sd">        second stage</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        covar_module: FITCKernel</span>
<span class="sd">            a FITC  kernel</span>
<span class="sd">        batch_shape: torch.size</span>
<span class="sd">            batch size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FITCMean</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">covar_module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_shape</span> <span class="o">=</span> <span class="n">batch_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">covar_module</span>

<div class="viewcode-block" id="FITCMean.forward"><a class="viewcode-back" href="../../../../../api/smac.model.gaussian_process.kernels.boing.html#smac.model.gaussian_process.kernels.boing.FITCMean.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the posterior mean from the cached value of FITC kernels</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input: torch.Tensor(N_xin, D)</span>
<span class="sd">            input torch Tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        res: torch.Tensor(N_xin)</span>
<span class="sd">            posterior mean value of FITC GP model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># detach is applied here to avoid updating the same parameter twice in the same iteration</span>
        <span class="c1"># which might result in an error</span>
        <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">covar_module</span><span class="o">.</span><span class="n">posterior_mean</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">res</span></div></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../../../_static/js/index.9ea38e314b9e6d9dab77.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 
    Copyright 2022, Marius Lindauer, Katharina Eggensperger,
    Matthias Feurer, Andr Biedenkapp, Difan Deng, Carolin Benjamins, Tim Ruhkopf, Ren Sass
    and Frank Hutter
.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a>
5.1.1. Template is modified version of <a
href="https://pydata-sphinx-theme.readthedocs.io">PyData Sphinx Theme</a>. <br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>