
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>smac.epm.gp_base_prior &#8212; SMAC3 Documentation 1.3.3 documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ac9c05f7c49ca1e1f876c6e36360ea26.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.9ea38e314b9e6d9dab77.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
  <a class="navbar-brand" href="../../../index.html">
    <img src="../../../_static/logo.png" class="logo" alt="logo">
  </a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/https://github.com/automl/SMAC3" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/automl_org?lang=de" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <form class="bd-search align-items-center" action="../../../search.html" method="get"
style="width: 100%;">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>

      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><h4 class="mt-0 mb-0">SMAC3 Documentation</h4>
<div class="mb-3">v1.3.3</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../getting_started/index.html">
   Getting Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../getting_started/installation.html">
     Installation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../getting_started/minimal_example.html">
     Minimal Example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../getting_started/package_overview.html">
     Package Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../getting_started/basic_usage.html">
     Basic Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/commandline/spear_qcp.html">
     SPEAR-QCP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/commandline/branin.html">
     Branin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/commandline/restore_branin.html">
     Restore Branin
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/spear_mf_instances.html">
     SPEAR-QCP with Multi-Fidelity on Instances
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_simple_multi_objective.html">
     Simple Multi-Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_synthetic_function.html">
     Synthetic Function with few Hyperparameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_svm_eips.html">
     SVM with EIPS as acquisition functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_gb_non_deterministic.html">
     Non-Deterministic Gradient-Boosting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_svm_cv.html">
     SVM with Cross-Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_sgd_instances.html">
     SGD on Instances
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_user_prior_mlp.html">
     HPO with User Priors over the Optimum
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_mlp_mf.html">
     MLP with Multi-Fidelity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../examples/python/plot_scalarized_multi_objective.html">
     Scalarized Multi-Objective Using ParEGO
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../details/index.html">
   Details
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/facades.html">
     Facades
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/target_algorithm_evaluator.html">
     Target Algorithm Evaluator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/scenario.html">
     Scenario
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/arguments.html">
     Arguments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/multi_objective.html">
     Multi-Objective Optimization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/run_history.html">
     Run-History
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/instances.html">
     Instances and Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/validation.html">
     Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/callbacks.html">
     Callbacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/parallelism.html">
     Parallelism
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/cuda.html">
     CUDA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../details/restoring.html">
     Restoring
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../api.html">
   API References
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.epm.html">
     smac.epm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.facade.html">
     smac.facade
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.initial_design.html">
     smac.initial_design
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.intensification.html">
     smac.intensification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.optimizer.html">
     smac.optimizer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.runhistory.html">
     smac.runhistory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.scenario.html">
     smac.scenario
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.smac_cli.html">
     smac.smac_cli
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.stats.html">
     smac.stats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.tae.html">
     smac.tae
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.callbacks.html">
     smac.callbacks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../api/smac.utils.html">
     smac.utils
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../glossary.html">
   Glossary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../faq.html">
   F.A.Q.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../../license.html">
   License
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for smac.epm.gp_base_prior</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">sps</span>

<span class="kn">from</span> <span class="nn">smac.utils.constants</span> <span class="kn">import</span> <span class="n">VERY_SMALL_NUMBER</span>

<span class="n">__copyright__</span> <span class="o">=</span> <span class="s2">&quot;Copyright 2021, AutoML.org Freiburg-Hannover&quot;</span>
<span class="n">__license__</span> <span class="o">=</span> <span class="s2">&quot;3-clause BSD&quot;</span>


<div class="viewcode-block" id="Prior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.Prior">[docs]</a><span class="k">class</span> <span class="nc">Prior</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Abstract base class to define the interface for priors of GP hyperparameter.</span>

<span class="sd">    This class is adapted from RoBO:</span>

<span class="sd">    Klein, A. and Falkner, S. and Mansur, N. and Hutter, F.</span>
<span class="sd">    RoBO: A Flexible and Robust Bayesian Optimization Framework in Python</span>
<span class="sd">    In: NIPS 2017 Bayesian Optimization Workshop</span>

<span class="sd">    [16.04.2019]: Whenever lnprob or the gradient is computed for a scalar input, we use math.* rather than np.*</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rng: np.random.RandomState</span>
<span class="sd">        Random number generator</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">rng</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Argument rng must not be `None`.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng</span> <span class="o">=</span> <span class="n">rng</span>

<div class="viewcode-block" id="Prior.lnprob"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.Prior.lnprob">[docs]</a>    <span class="k">def</span> <span class="nf">lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the log probability of theta.</span>

<span class="sd">        Theta must be on a log scale! This method exponentiates theta and calls ``self._lnprob``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            Hyperparameter configuration in log space.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The log probability of theta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lnprob</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="nf">_lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the log probability of theta.</span>

<span class="sd">        Theta must be on the original scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            Hyperparameter configuration on the original scale.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The log probability of theta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

<div class="viewcode-block" id="Prior.sample_from_prior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.Prior.sample_from_prior">[docs]</a>    <span class="k">def</span> <span class="nf">sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns ``n_samples`` from the prior.</span>

<span class="sd">        All samples are on a log scale. This method calls ``self._sample_from_prior`` and applies a log transformation</span>
<span class="sd">        to the obtained values.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;argument n_samples needs to be a scalar (is </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;argument n_samples needs to be positive (is </span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">n_samples</span><span class="p">)</span>

        <span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_sample_from_prior</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">sample</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sample </span><span class="si">%s</span><span class="s2"> from prior </span><span class="si">%s</span><span class="s2"> contains infinite values!&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="bp">self</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">sample</span></div>

    <span class="k">def</span> <span class="nf">_sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns ``n_samples`` from the prior.</span>

<span class="sd">        All samples are on a original scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

<div class="viewcode-block" id="Prior.gradient"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.Prior.gradient">[docs]</a>    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the gradient of the prior with respect to theta.</span>

<span class="sd">        Theta must be on the original scale.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            Hyperparameter configuration in log space</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The gradient of the prior at theta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_gradient</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="nf">_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the gradient of the prior with respect to theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            Hyperparameter configuration in the original space space</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The gradient of the prior at theta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>


<div class="viewcode-block" id="TophatPrior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.TophatPrior">[docs]</a><span class="k">class</span> <span class="nc">TophatPrior</span><span class="p">(</span><span class="n">Prior</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lower_bound</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tophat prior as it used in the original spearmint code.</span>

<span class="sd">        This class is adapted from RoBO:</span>

<span class="sd">        Klein, A. and Falkner, S. and Mansur, N. and Hutter, F.</span>
<span class="sd">        RoBO: A Flexible and Robust Bayesian Optimization Framework in Python</span>
<span class="sd">        In: NIPS 2017 Bayesian Optimization Workshop</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lower_bound : float</span>
<span class="sd">            Lower bound of the prior. In original scale.</span>
<span class="sd">        upper_bound : float</span>
<span class="sd">            Upper bound of the prior. In original scale.</span>
<span class="sd">        rng: np.random.RandomState</span>
<span class="sd">            Random number generator</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min</span> <span class="o">=</span> <span class="n">lower_bound</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lower_bound</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="n">upper_bound</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Upper bound of Tophat prior must be greater than the lower bound!&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the log probability of theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            A hyperparameter configuration</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min</span> <span class="ow">or</span> <span class="n">theta</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return ``n_samples`` from the prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;argument n_samples needs to be a scalar (is </span><span class="si">%s</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;argument n_samples needs to be positive (is </span><span class="si">%d</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">n_samples</span><span class="p">)</span>

        <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_min</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_max</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,)))</span>
        <span class="k">return</span> <span class="n">p0</span>

<div class="viewcode-block" id="TophatPrior.gradient"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.TophatPrior.gradient">[docs]</a>    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the gradient of the prior with respect to theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            Hyperparameter configuration in log space</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        (D) np.array</span>

<span class="sd">            The gradient of the prior at theta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mi">0</span></div></div>


<div class="viewcode-block" id="HorseshoePrior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.HorseshoePrior">[docs]</a><span class="k">class</span> <span class="nc">HorseshoePrior</span><span class="p">(</span><span class="n">Prior</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Horseshoe Prior as it is used in spearmint.</span>

<span class="sd">        This class is adapted from RoBO:</span>

<span class="sd">        Klein, A. and Falkner, S. and Mansur, N. and Hutter, F.</span>
<span class="sd">        RoBO: A Flexible and Robust Bayesian Optimization Framework in Python</span>
<span class="sd">        In: NIPS 2017 Bayesian Optimization Workshop</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        scale: float</span>
<span class="sd">            Scaling parameter. See below how it is influencing the distribution.</span>
<span class="sd">        rng: np.random.RandomState</span>
<span class="sd">            Random number generator</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_square</span> <span class="o">=</span> <span class="n">scale</span><span class="o">**</span><span class="mi">2</span>

    <span class="k">def</span> <span class="nf">_lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the log probability of theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : (D,) numpy array</span>
<span class="sd">            A hyperparameter configuration</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We computed it exactly as in the original spearmint code, they basically say that there&#39;s no analytical form</span>
        <span class="c1"># of the horseshoe prior, but that the multiplier is bounded between 2 and 4 and that they used the middle</span>
        <span class="c1"># See &quot;The horseshoe estimator for sparse signals&quot; by Carvalho, Poloson and Scott (2010), Equation 1.</span>
        <span class="c1"># https://www.jstor.org/stable/25734098</span>
        <span class="c1"># Compared to the paper by Carvalho, there&#39;s a constant multiplicator missing</span>
        <span class="c1"># Compared to Spearmint we first have to undo the log space transformation of the theta</span>
        <span class="c1"># Note: &quot;undo log space transformation&quot; is done in parent class</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>  <span class="c1"># POSITIVE infinity (this is the &quot;spike&quot;)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_square</span> <span class="o">/</span> <span class="n">theta</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="n">VERY_SMALL_NUMBER</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns N samples from the prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This is copied from RoBO - scale is most likely the tau parameter</span>
        <span class="n">lamda</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">standard_cauchy</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">))</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="n">lamda</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p0</span>

    <span class="k">def</span> <span class="nf">_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the gradient of the prior with respect to theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : (D,) numpy array</span>
<span class="sd">            Hyperparameter configuration</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        (D) np.array</span>
<span class="sd">            The gradient of the prior at theta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>  <span class="c1"># POSITIVE infinity (this is the &quot;spike&quot;)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="mi">6</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_square</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_square</span> <span class="o">+</span> <span class="n">theta</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">b</span> <span class="o">*=</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_square</span> <span class="o">*</span> <span class="n">theta</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mf">1e-14</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">a</span> <span class="o">/</span> <span class="n">b</span></div>


<div class="viewcode-block" id="LognormalPrior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.LognormalPrior">[docs]</a><span class="k">class</span> <span class="nc">LognormalPrior</span><span class="p">(</span><span class="n">Prior</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sigma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">,</span>
        <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Log normal prior.</span>

<span class="sd">        This class is adapted from RoBO:</span>

<span class="sd">        Klein, A. and Falkner, S. and Mansur, N. and Hutter, F.</span>
<span class="sd">        RoBO: A Flexible and Robust Bayesian Optimization Framework in Python</span>
<span class="sd">        In: NIPS 2017 Bayesian Optimization Workshop</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        sigma: float</span>
<span class="sd">            Specifies the standard deviation of the normal</span>
<span class="sd">            distribution.</span>
<span class="sd">        rng: np.random.RandomState</span>
<span class="sd">            Random number generator</span>
<span class="sd">        mean: float</span>
<span class="sd">            Specifies the mean of the normal distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mean</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">mean</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_square</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sqrt_2_pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the log probability of theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            A hyperparameter configuration</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1e25</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rval</span> <span class="o">=</span> <span class="o">-</span><span class="p">((</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_square</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sqrt_2_pi</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">theta</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">rval</span>

    <span class="k">def</span> <span class="nf">_sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns N samples from the prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the gradient of the prior with respect to theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : (D,) numpy array</span>
<span class="sd">            Hyperparameter configuration in log space</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        (D) np.array</span>
<span class="sd">            The gradient of the prior at theta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># derivative of log(1 / (x * s^2 * sqrt(2 pi)) * exp( - 0.5 * (log(x ) / s^2))^2))</span>
            <span class="c1"># This is without the mean!!!</span>
            <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma_square</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma_square</span> <span class="o">*</span> <span class="p">(</span><span class="n">theta</span><span class="p">))</span> <span class="o">*</span> <span class="n">theta</span></div>


<div class="viewcode-block" id="SoftTopHatPrior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.SoftTopHatPrior">[docs]</a><span class="k">class</span> <span class="nc">SoftTopHatPrior</span><span class="p">(</span><span class="n">Prior</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lower_bound</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">upper_bound</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">exponent</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;error&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lower_bound</span> <span class="o">=</span> <span class="n">lower_bound</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_lower_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">lower_bound</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">RuntimeWarning</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;invalid value encountered in log&quot;</span> <span class="ow">in</span> <span class="n">w</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid lower bound </span><span class="si">%f</span><span class="s2"> (cannot compute log)&quot;</span> <span class="o">%</span> <span class="n">lower_bound</span><span class="p">)</span>

                <span class="k">raise</span> <span class="n">w</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upper_bound</span> <span class="o">=</span> <span class="n">upper_bound</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_log_upper_bound</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">upper_bound</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">RuntimeWarning</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;invalid value encountered in log&quot;</span> <span class="ow">in</span> <span class="n">w</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid lower bound </span><span class="si">%f</span><span class="s2"> (cannot compute log)&quot;</span> <span class="o">%</span> <span class="n">lower_bound</span><span class="p">)</span>

                <span class="k">raise</span> <span class="n">w</span>

        <span class="k">if</span> <span class="n">exponent</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Exponent cannot be less or equal than zero (but is </span><span class="si">%f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">exponent</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">=</span> <span class="n">exponent</span>

<div class="viewcode-block" id="SoftTopHatPrior.lnprob"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.SoftTopHatPrior.lnprob">[docs]</a>    <span class="k">def</span> <span class="nf">lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return the log probability of theta.&quot;&quot;&quot;</span>
        <span class="c1"># We need to use lnprob here instead of _lnprob to have the squared function work</span>
        <span class="c1"># in the logarithmic space, too.</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_lower_bound</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="p">((</span><span class="n">theta</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_lower_bound</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">theta</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_upper_bound</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_upper_bound</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns N samples from the prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_lower_bound</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_upper_bound</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,)))</span>

<div class="viewcode-block" id="SoftTopHatPrior.gradient"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.SoftTopHatPrior.gradient">[docs]</a>    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the gradient of the prior at theta.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">theta</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_lower_bound</span><span class="p">:</span>
                <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">*</span> <span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_lower_bound</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">theta</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_upper_bound</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponent</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_upper_bound</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;SoftTopHatPrior(lower_bound=</span><span class="si">%f</span><span class="s2">, upper_bound=</span><span class="si">%f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lower_bound</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">upper_bound</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="GammaPrior"><a class="viewcode-back" href="../../../api/smac.epm.gp_base_prior.html#smac.epm.gp_base_prior.GammaPrior">[docs]</a><span class="k">class</span> <span class="nc">GammaPrior</span><span class="p">(</span><span class="n">Prior</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gamma prior.</span>

<span class="sd">        f(x) = (x-loc)**(a-1) * e**(-(x-loc)) * (1/scale)**a / gamma(a)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        a: float &gt; 0</span>
<span class="sd">            shape parameter</span>
<span class="sd">        scale: float &gt; 0</span>
<span class="sd">            scale parameter (1/scale corresponds to parameter p in canonical form)</span>
<span class="sd">        loc: float</span>
<span class="sd">            mean parameter for the distribution</span>
<span class="sd">        rng: np.random.RandomState</span>
<span class="sd">            Random number generator</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">rng</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">a</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="n">loc</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span>

    <span class="k">def</span> <span class="nf">_lnprob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns the logpdf of theta.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : float</span>
<span class="sd">            Hyperparameter configuration</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">sps</span><span class="o">.</span><span class="n">gamma</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sample_from_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Returns N samples from the prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            The number of samples that will be drawn.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;As computed by Wolfram Alpha.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta: float</span>
<span class="sd">            A hyperparameter configuration</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Multiply by theta because of the chain rule...</span>
            <span class="k">return</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">theta</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">))</span> <span class="o">*</span> <span class="n">theta</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.9ea38e314b9e6d9dab77.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 
    Copyright 2022, Marius Lindauer, Katharina Eggensperger,
    Matthias Feurer, Andr Biedenkapp, Difan Deng, Carolin Benjamins, Tim Ruhkopf, Ren Sass
    and Frank Hutter
.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a>
4.5.0. Template is modified version of <a
href="https://pydata-sphinx-theme.readthedocs.io">PyData Sphinx Theme</a>. <br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>